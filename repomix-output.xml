This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.jupyter/
  desktop-workspaces/
    default-37a8.jupyterlab-workspace
.virtual_documents/
  AI_News_Chatbot_ADK_Tutorial.ipynb
ai_news_chatbot_adk/
  __init__.py
  agent.py
.env.example
.repomixignore
AI_News_Chatbot_ADK_Tutorial_BACKUP.ipynb
AI_News_Chatbot_ADK_Tutorial.ipynb
backend_server.py
IMPLEMENTATION_PLAN.md
README.md
repomix.config.json
requirements.txt
run_all.sh
run_backend.sh
run_frontend.sh
run.sh
SETUP_GUIDE.md
streamlit_app.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".jupyter/desktop-workspaces/default-37a8.jupyterlab-workspace">
{"data":{"file-browser-filebrowser:columns":{"sizes":{"name":88,"file_size":60,"is_selected":18,"last_modified":60}},"layout-restorer:data":{"main":{"dock":{"type":"tab-area","currentIndex":0,"widgets":["notebook:AI_News_Chatbot_ADK_Tutorial.ipynb","editor:run.sh","notebook:AI_News_Chatbot_ADK_Tutorial_BACKUP.ipynb"]},"current":"notebook:AI_News_Chatbot_ADK_Tutorial.ipynb"},"down":{"size":0,"widgets":[]},"left":{"collapsed":false,"visible":true,"current":"filebrowser","widgets":["filebrowser","running-sessions","@jupyterlab/toc:plugin","extensionmanager.main-view","jupyter-ai-chat"],"widgetStates":{"jp-running-sessions":{"sizes":[0.16666666666666666,0.16666666666666666,0.16666666666666666,0.16666666666666666,0.16666666666666666,0.16666666666666666],"expansionStates":[false,false,false,false,false,false]},"extensionmanager.main-view":{"sizes":[0,0.5,0.5],"expansionStates":[false,false,false]}}},"right":{"collapsed":true,"visible":true,"widgets":["jp-property-inspector"],"widgetStates":{}},"relativeSizes":[0.17370242214532872,0.8262975778546713,0],"top":{"simpleVisibility":true}},"docmanager:recents":{"opened":[{"path":"","contentType":"directory","root":"~/demo/ai_news_chatbot_adk"},{"path":"AI_News_Chatbot_ADK_Tutorial.ipynb","contentType":"notebook","factory":"Notebook","root":"~/demo/ai_news_chatbot_adk"},{"path":"AI_News_Chatbot_ADK_Tutorial_BACKUP.ipynb","contentType":"notebook","factory":"Notebook","root":"~/demo/ai_news_chatbot_adk"},{"path":"run.sh","contentType":"file","factory":"Editor","root":"~/demo/ai_news_chatbot_adk"}],"closed":[{"path":"AI_News_Chatbot_ADK_Tutorial.ipynb","contentType":"notebook","factory":"Notebook","root":"~/demo/ai_news_chatbot_adk"}]},"notebook:AI_News_Chatbot_ADK_Tutorial.ipynb":{"data":{"path":"AI_News_Chatbot_ADK_Tutorial.ipynb","factory":"Notebook"}},"editor:run.sh":{"data":{"path":"run.sh","factory":"Editor"}},"notebook:AI_News_Chatbot_ADK_Tutorial_BACKUP.ipynb":{"data":{"path":"AI_News_Chatbot_ADK_Tutorial_BACKUP.ipynb","factory":"Notebook"}}},"metadata":{"id":"default"}}
</file>

<file path=".virtual_documents/AI_News_Chatbot_ADK_Tutorial.ipynb">
#@title üü¢ **Step 1: Install Google ADK and NEW google-genai SDK** { display-mode: "form" }
#@markdown Run this cell to install all required packages.

import subprocess
import sys

def install_packages():
    """Install required packages for ADK with NEW google-genai SDK"""
    packages = [
        "google-genai",          # NEW unified Google Gen AI SDK (replaces google-generativeai)
        "google-adk",            # ADK package
        "python-dotenv>=1.0.0",
        "ipywidgets>=8.0.0",
        "nest-asyncio>=1.5.0"
    ]
    
    print("üîß Installing packages...")
    print("üìå NOTE: Installing google-genai (NEW), NOT google-generativeai (deprecated)\n")
    
    for package in packages:
        print(f"  Installing {package}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", package])
    
    print("\n‚úÖ All packages installed successfully!")
    print("\nüì¶ Installed packages:")
    for package in packages:
        print(f"  ‚Ä¢ {package}")
    print("\nüÜï Using google-genai - the new unified SDK")

install_packages()

# Enable nested async for Colab
import nest_asyncio
nest_asyncio.apply()

print("\nüéâ Environment ready with NEW google-genai SDK!")


#@title üü¢ **Step 2: Set Up Your Google API Key** { display-mode: "form" }
#@markdown Enter your Google API key below. Get one free at [Google AI Studio](https://ai.google.dev/)

import os
from IPython.display import display, HTML, clear_output
import ipywidgets as widgets

# Set API key
API_KEY = 'AIzaSyDsr7AV9z3lKLOrHsWa5OepP0b7WMXGtEo'  # Your API key

# Set environment variables - google-genai automatically uses these
os.environ['GEMINI_API_KEY'] = API_KEY  # Primary env var for new SDK
os.environ['GOOGLE_API_KEY'] = API_KEY  # Fallback env var

print("‚úÖ API Key set successfully!")
print("üîí Your key is stored securely for this session.")

# Test the NEW google-genai SDK
print("\nüß™ Testing google-genai SDK...")
try:
    from google import genai
    from google.genai import types
    
    # Create client - automatically uses GEMINI_API_KEY or GOOGLE_API_KEY
    client = genai.Client()  # No need to pass API key, uses env vars
    
    # Test with simple generation
    response = client.models.generate_content(
        model='gemini-1.5-flash',
        contents='Say "API configured successfully" in exactly 3 words'
    )
    print(f"‚úÖ Test response: {response.text}")
    print("‚úÖ google-genai SDK is working correctly!")
    
except Exception as e:
    print(f"‚ö†Ô∏è Error: {e}")
    print("Please check your API key and try again")

# Display helpful information
display(HTML("""
<div style='background-color: #e3f2fd; padding: 15px; border-radius: 5px; margin-top: 10px;'>
    <h4>üí° Configuration Details:</h4>
    <ul>
        <li>‚úÖ Using google-genai SDK (NEW unified SDK)</li>
        <li>‚úÖ API key set as GEMINI_API_KEY environment variable</li>
        <li>‚úÖ Client auto-detects API key from environment</li>
        <li>‚ùå NOT using google-generativeai (deprecated)</li>
    </ul>
</div>
"""))





#@title üîµ **ADK & google-genai Concepts** { display-mode: "form" }
#@markdown Learn about ADK components and the new SDK

from IPython.display import display, HTML

print("""üìö KEY CONCEPTS (2024-2025)

1. üÜï GOOGLE-GENAI SDK
   ‚Ä¢ NEW unified SDK replacing google-generativeai
   ‚Ä¢ Client-based architecture: genai.Client()
   ‚Ä¢ Auto-detects API keys from environment
   ‚Ä¢ Supports both Google AI and Vertex AI
   ‚Ä¢ General Availability (GA) as of May 2025

2. ü§ñ ADK AGENTS
   ‚Ä¢ LlmAgent: Language model powered agents
   ‚Ä¢ Agent: Base agent class
   ‚Ä¢ Support for Gemini 2.0 and 2.5 models

3. üîß TOOLS
   ‚Ä¢ google_search: Web search capability
   ‚Ä¢ Custom functions as tools
   ‚Ä¢ AgentTool: Use other agents as tools

4. üß† MODELS
   ‚Ä¢ gemini-1.5-flash: Fast, efficient
   ‚Ä¢ gemini-1.5-pro: Advanced reasoning
   ‚Ä¢ gemini-2.0-flash: Latest with search support
""")

# Show the NEW SDK pattern
print("\nüìù NEW google-genai Usage Pattern:")
print("""
from google import genai
from google.genai import types

# Client automatically uses GEMINI_API_KEY or GOOGLE_API_KEY
client = genai.Client()

response = client.models.generate_content(
    model='gemini-2.0-flash',
    contents='Your prompt here',
    config=types.GenerateContentConfig(
        max_output_tokens=400,
        temperature=0.5
    )
)
""")

print("‚úÖ This is the modern, recommended approach!")





#@title üü¢ **Create a Simple Hello World Agent** { display-mode: "form" }
#@markdown This agent uses the NEW google-genai SDK!

import os
from google import genai
from google.genai import types

# Verify API key is set
if 'GEMINI_API_KEY' not in os.environ and 'GOOGLE_API_KEY' not in os.environ:
    print("‚ùå Please set your API key in Step 2 first!")
else:
    # Create a simple agent wrapper using google-genai
    class SimpleAgent:
        def __init__(self, name, model, description, instruction):
            self.name = name
            self.model_name = model
            self.description = description
            self.instruction = instruction
            # Create client - automatically uses env vars
            self.client = genai.Client()
        
        def query(self, message):
            """Send query using NEW google-genai SDK"""
            prompt = f"{self.instruction}\n\nUser: {message}\nAssistant:"
            
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.7,
                    max_output_tokens=256
                )
            )
            return response.text
    
    # Create hello agent
    hello_agent = SimpleAgent(
        name="hello_agent",
        model="gemini-1.5-flash",
        description="A friendly agent that greets users",
        instruction="You are a friendly assistant. Greet users warmly and ask how you can help them today. Keep responses brief and cheerful."
    )
    
    print("‚úÖ Simple agent created with google-genai SDK!")
    print("\nüìã Agent Details:")
    print(f"  ‚Ä¢ Name: {hello_agent.name}")
    print(f"  ‚Ä¢ Model: {hello_agent.model_name}")
    print(f"  ‚Ä¢ Description: {hello_agent.description}")
    print(f"  ‚Ä¢ SDK: google-genai (NEW unified SDK)")
    print("\nüéØ Try running the next cell to test it!")


#@title üü° **Test Your Hello Agent** { display-mode: "form" }
#@markdown Enter a message to send to your agent

test_message = "Hello!" #@param {type:"string"}

if 'hello_agent' in globals():
    print(f"üë§ You: {test_message}")
    print("\nü§ñ Agent is thinking (using google-genai SDK)...\n")
    
    try:
        # Run the agent
        response = hello_agent.query(test_message)
        print(f"ü§ñ Agent: {response}")
        print("\n‚úÖ Response generated with NEW google-genai SDK!")
    except Exception as e:
        print(f"‚ö†Ô∏è Error: {e}")
        print("Please check your API key configuration")
else:
    print("‚ùå Please create the agent first by running the previous cell!")





#@title üü¢ **Create the AI News Agent** { display-mode: "form" }
#@markdown This agent uses the NEW google-genai SDK for AI news!

from google import genai
from google.genai import types
from typing import Optional, List, Dict
import json

class AINewsAgent:
    """AI News Agent using NEW google-genai SDK"""
    
    def __init__(self):
        self.name = "ai_news_agent"
        self.model_name = "gemini-1.5-flash"
        self.description = "Agent that provides the latest AI news and information"
        self.instruction = """You are an AI news assistant. Your primary role is to provide accurate, 
        up-to-date information about artificial intelligence developments, news, and trends.
        
        When asked about AI news or developments:
        1. Provide informative and comprehensive responses
        2. Include recent developments and breakthroughs
        3. Mention relevant companies, researchers, or technologies
        4. Explain technical concepts clearly
        5. If information might be outdated, acknowledge this limitation
        
        Always maintain a helpful, informative tone and focus on delivering factual information."""
        
        # Initialize google-genai client (uses env vars automatically)
        self.client = genai.Client()
    
    def query(self, message: str) -> str:
        """Process a query using google-genai SDK"""
        prompt = f"{self.instruction}\n\nUser Query: {message}\n\nProvide a comprehensive response:"
        
        try:
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.7,
                    max_output_tokens=800,
                    top_p=0.95
                )
            )
            return response.text
        except Exception as e:
            return f"I encountered an issue: {e}. Please try again."
    
    def get_news(self, topic: str = "latest AI developments") -> str:
        """Get news about a specific AI topic"""
        prompt = f"{self.instruction}\n\nProvide a detailed update about: {topic}\n\nInclude recent developments, key players, and implications:"
        
        response = self.client.models.generate_content(
            model=self.model_name,
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=0.6,
                max_output_tokens=1000
            )
        )
        return response.text
    
    def analyze_trend(self, trend: str) -> str:
        """Analyze a specific AI trend"""
        analysis_prompt = f"Analyze this AI trend in detail: {trend}. Discuss current state, challenges, opportunities, and future outlook."
        return self.query(analysis_prompt)

# Create the AI News Agent
ai_news_agent = AINewsAgent()

print("üéâ AI News Agent created successfully with google-genai SDK!")
print("\nüîß Agent Configuration:")
print(f"  ‚Ä¢ Name: {ai_news_agent.name}")
print(f"  ‚Ä¢ Model: {ai_news_agent.model_name}")
print(f"  ‚Ä¢ SDK: google-genai (NEW unified SDK)")
print("\nüì∞ Available methods:")
print("  ‚Ä¢ agent.query(message) - Ask any question about AI")
print("  ‚Ä¢ agent.get_news(topic) - Get news on specific topic")
print("  ‚Ä¢ agent.analyze_trend(trend) - Analyze AI trends")

# Store as root_agent for ADK compatibility
root_agent = ai_news_agent





#@title üü¢ **Interactive AI News Chat Interface** { display-mode: "form" }
#@markdown Chat with your AI News Agent powered by google-genai!

from IPython.display import display, HTML, Markdown
import ipywidgets as widgets
from datetime import datetime

if 'ai_news_agent' not in globals():
    print("‚ùå Please create the AI News Agent first!")
else:
    # Create interactive widgets
    print("üí¨ AI News Chat Interface (Powered by google-genai SDK)")
    print("=" * 60)
    
    # Quick prompts
    quick_prompts = [
        'üì∞ Latest AI News',
        'ü§ñ GPT & LLM Updates',
        'üß† Google Gemini News',
        'üî¨ AI Research Breakthroughs',
        'üíº AI in Business',
        'üîÆ AI Trends 2025'
    ]
    
    prompts_map = {
        'üì∞ Latest AI News': "What are the latest AI news and developments?",
        'ü§ñ GPT & LLM Updates': "What's new with GPT and language models?",
        'üß† Google Gemini News': "Tell me about Google's Gemini models and updates",
        'üî¨ AI Research Breakthroughs': "What are recent AI research breakthroughs?",
        'üíº AI in Business': "How is AI being used in business today?",
        'üîÆ AI Trends 2025': "What are the top AI trends for 2025?"
    }
    
    # Create UI elements
    quick_buttons = widgets.ToggleButtons(
        options=quick_prompts,
        description='Quick:',
        disabled=False,
        button_style='info'
    )
    
    custom_input = widgets.Text(
        value='',
        placeholder='Or type your own question about AI...',
        description='Custom:',
        style={'description_width': 'initial'}
    )
    
    output_area = widgets.Output()
    
    def process_query(b=None):
        with output_area:
            output_area.clear_output()
            
            # Get query
            if custom_input.value:
                query = custom_input.value
                custom_input.value = ''
            elif quick_buttons.value:
                query = prompts_map[quick_buttons.value]
            else:
                print("Please select a quick prompt or type a custom question.")
                return
            
            print(f"üìù Query: {query}")
            print(f"‚è∞ Time: {datetime.now().strftime('%H:%M:%S')}")
            print("\n" + "=" * 50)
            print("\n‚è≥ Processing with google-genai SDK...\n")
            
            try:
                # Get response
                response = ai_news_agent.query(query)
                
                print("ü§ñ AI News Agent Response:")
                print("=" * 50)
                display(Markdown(response))
                print("=" * 50)
                print("\n‚úÖ Response generated successfully!")
                print(f"üìä Response length: {len(response.split())} words")
                
            except Exception as e:
                print(f"‚ùå Error: {e}")
    
    # Create button
    ask_button = widgets.Button(
        description='Ask Agent',
        button_style='primary',
        icon='paper-plane'
    )
    ask_button.on_click(process_query)
    
    # Display interface
    display(quick_buttons)
    display(custom_input)
    display(ask_button)
    display(output_area)
    
    print("\nüìù Tips:")
    print("  ‚Ä¢ Select a quick prompt or type your own question")
    print("  ‚Ä¢ Click 'Ask Agent' to get response")
    print("  ‚Ä¢ Using NEW google-genai SDK for all responses")





#@title üü° **Agent Testing Suite** { display-mode: "form" }
#@markdown Test your agent with different query types

import time

test_queries = [
    {"type": "Recent News", "query": "What happened in AI this week?"},
    {"type": "Company Updates", "query": "Latest news about OpenAI and Google AI"},
    {"type": "Technical", "query": "Explain how transformer models work"},
    {"type": "Trends", "query": "What are the AI trends for 2025?"},
    {"type": "Ethics", "query": "What are current AI ethics concerns?"}
]

query_type = "Recent News" #@param ["Recent News", "Company Updates", "Technical", "Trends", "Ethics", "All"]
run_test = True #@param {type:"boolean"}

if run_test and 'ai_news_agent' in globals():
    if query_type == "All":
        tests_to_run = test_queries
    else:
        tests_to_run = [q for q in test_queries if q["type"] == query_type]
    
    print(f"üß™ Testing Agent with google-genai SDK")
    print(f"Running {len(tests_to_run)} test(s)\n")
    print("=" * 60)
    
    for test in tests_to_run:
        print(f"\nüìä Test Type: {test['type']}")
        print(f"üìù Query: {test['query']}")
        print("-" * 40)
        
        start_time = time.time()
        
        try:
            # Run query
            response = ai_news_agent.query(test['query'])
            elapsed_time = time.time() - start_time
            
            # Display response (truncated)
            if len(response) > 300:
                print(f"Response: {response[:300]}...\n[Truncated - {len(response)} chars total]")
            else:
                print(f"Response: {response}")
            
            print(f"\n‚è±Ô∏è Response time: {elapsed_time:.2f} seconds")
            print(f"üìè Word count: {len(response.split())} words")
            print("‚úÖ Test passed")
            
        except Exception as e:
            print(f"‚ùå Test failed: {e}")
        
        print("=" * 60)
    
    print("\nüéØ Testing complete!")
    print("‚úÖ All tests used google-genai SDK")
elif not run_test:
    print("‚ÑπÔ∏è Set run_test to True to run the tests")
else:
    print("‚ùå Please create the AI News Agent first!")





#@title üü° **Create Specialized News Agents** { display-mode: "form" }
#@markdown Create multiple specialized agents using google-genai SDK

from google import genai
from google.genai import types

class SpecializedAgent:
    """Specialized agent using google-genai SDK"""
    
    def __init__(self, name: str, focus_area: str, special_instructions: str):
        self.name = name
        self.focus_area = focus_area
        self.client = genai.Client()  # Uses env vars automatically
        self.instructions = f"""You are an AI expert specializing in {focus_area}.
        {special_instructions}
        Provide detailed, accurate, and insightful responses."""
    
    def query(self, message: str) -> str:
        prompt = f"{self.instructions}\n\nQuery: {message}\n\nExpert Response:"
        
        response = self.client.models.generate_content(
            model='gemini-1.5-flash',
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=0.7,
                max_output_tokens=600
            )
        )
        return response.text

# Create specialized agents
specialized_agents = {
    "research": SpecializedAgent(
        "AI Research Expert",
        "AI research papers and academic developments",
        "Focus on recent papers, breakthroughs, and research trends. Explain complex concepts clearly."
    ),
    "business": SpecializedAgent(
        "AI Business Analyst",
        "AI in business and industry applications",
        "Discuss AI adoption, ROI, use cases, and business transformations. Include market analysis."
    ),
    "ethics": SpecializedAgent(
        "AI Ethics Specialist",
        "AI ethics, safety, and governance",
        "Address ethical concerns, bias, fairness, and responsible AI development. Consider societal impacts."
    ),
    "technical": SpecializedAgent(
        "AI Technical Expert",
        "technical implementation and architecture",
        "Explain technical details, architectures, and implementation strategies. Include practical examples."
    )
}

print("‚úÖ Specialized Agents Created with google-genai SDK!")
print("\nü§ñ Available Specialists:")
for key, agent in specialized_agents.items():
    print(f"  ‚Ä¢ {agent.name}: {agent.focus_area}")

print("\nüí° Usage: specialized_agents['research'].query('your question')")
print("\nüìå All agents use the NEW google-genai SDK")

# Quick test
print("\nüß™ Quick Test - Research Agent:")
print("-" * 40)
try:
    test_response = specialized_agents["research"].query("What are the latest breakthroughs in LLM research?")
    print(test_response[:200] + "..." if len(test_response) > 200 else test_response)
except Exception as e:
    print(f"Test note: {e}")


#@title üü° **Multi-Agent Collaboration System** { display-mode: "form" }
#@markdown Create a system where multiple agents collaborate

from google import genai
from google.genai import types

class MultiAgentSystem:
    """Multi-agent collaboration using google-genai SDK"""
    
    def __init__(self, agents_dict):
        self.agents = agents_dict
        self.client = genai.Client()  # Coordinator client
    
    def route_query(self, query: str) -> str:
        """Route query to appropriate specialist"""
        routing_prompt = f"""Analyze this query and determine which expert should answer:
        '{query}'
        
        Options:
        - research: For papers, academic research
        - business: For industry, market, ROI
        - ethics: For bias, safety, societal impacts
        - technical: For implementation, architecture
        
        Respond with just one word: research, business, ethics, or technical."""
        
        response = self.client.models.generate_content(
            model='gemini-1.5-flash',
            contents=routing_prompt,
            config=types.GenerateContentConfig(
                temperature=0.3,
                max_output_tokens=10
            )
        )
        
        agent_type = response.text.strip().lower()
        if agent_type not in self.agents:
            agent_type = "research"  # Default
        
        return agent_type
    
    def collaborative_response(self, query: str) -> str:
        """Get collaborative response from multiple agents"""
        # Determine primary agent
        primary_type = self.route_query(query)
        primary_agent = self.agents[primary_type]
        
        print(f"üéØ Primary Expert: {primary_agent.name}")
        
        # Get primary response
        primary_response = primary_agent.query(query)
        
        # Get complementary perspective
        if primary_type != "ethics":
            ethics_perspective = self.agents["ethics"].query(f"What are the ethical considerations of: {query}")
            return f"**{primary_agent.name}:**\n{primary_response}\n\n**Ethical Considerations:**\n{ethics_perspective[:200]}..."
        else:
            return f"**{primary_agent.name}:**\n{primary_response}"

if 'specialized_agents' in globals():
    multi_agent_system = MultiAgentSystem(specialized_agents)
    
    print("üéØ Multi-Agent System Ready!")
    print("Using google-genai SDK for all agents\n")
    
    # Test the system
    test_query = "How will AI impact healthcare in 2025?"
    print(f"Test Query: {test_query}")
    print("=" * 50)
    
    try:
        result = multi_agent_system.collaborative_response(test_query)
        display(Markdown(result[:600] + "..." if len(result) > 600 else result))
    except Exception as e:
        print(f"Note: {e}")
else:
    print("‚ùå Please create specialized agents first!")





#@title üîµ **Export Your Agent for Deployment** { display-mode: "form" }
#@markdown Generate deployment-ready code using google-genai SDK

deployment_type = "Streamlit App" #@param ["Streamlit App", "FastAPI Server", "Flask App", "ADK Web"]

deployment_code = {
    "Streamlit App": """# streamlit_app.py - AI News Bot with google-genai SDK
import streamlit as st
from google import genai
from google.genai import types
import os

st.set_page_config(page_title="AI News Bot", page_icon="ü§ñ")

# Initialize google-genai client
@st.cache_resource
def init_client():
    # Client auto-detects GEMINI_API_KEY or GOOGLE_API_KEY
    return genai.Client()

client = init_client()

st.title("ü§ñ AI News Chatbot")
st.caption("Powered by google-genai SDK (NEW unified SDK)")

# Chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# Chat input
if prompt := st.chat_input("Ask about AI news..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)
    
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            response = client.models.generate_content(
                model='gemini-1.5-flash',
                contents=f"As an AI news expert, answer: {prompt}",
                config=types.GenerateContentConfig(
                    temperature=0.7,
                    max_output_tokens=800
                )
            )
        st.write(response.text)
    
    st.session_state.messages.append(
        {"role": "assistant", "content": response.text}
    )

# Run: streamlit run streamlit_app.py
""",

    "FastAPI Server": """# fastapi_server.py - API with google-genai SDK
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from google import genai
from google.genai import types
import os

app = FastAPI(title="AI News API")

# Initialize client
client = genai.Client()  # Auto-detects API key from env

class ChatRequest(BaseModel):
    message: str

class ChatResponse(BaseModel):
    response: str

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    try:
        response = client.models.generate_content(
            model='gemini-1.5-flash',
            contents=f"AI expert response to: {request.message}",
            config=types.GenerateContentConfig(
                temperature=0.7,
                max_output_tokens=800
            )
        )
        return ChatResponse(response=response.text)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health():
    return {"status": "healthy", "sdk": "google-genai"}

# Run: uvicorn fastapi_server:app --reload
""",

    "Flask App": """# flask_app.py - Flask with google-genai SDK
from flask import Flask, request, jsonify, render_template
from google import genai
from google.genai import types
import os

app = Flask(__name__)

# Initialize client
client = genai.Client()

@app.route('/')
def index():
    return "<h1>AI News API - Powered by google-genai SDK</h1>"

@app.route('/chat', methods=['POST'])
def chat():
    try:
        data = request.json
        message = data['message']
        
        response = client.models.generate_content(
            model='gemini-1.5-flash',
            contents=f"AI expert response: {message}",
            config=types.GenerateContentConfig(
                temperature=0.7,
                max_output_tokens=800
            )
        )
        
        return jsonify({'response': response.text})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)

# Run: python flask_app.py
""",

    "ADK Web": """# agent.py - ADK with google-genai SDK
from google.adk.agents import LlmAgent
from google import genai
from google.genai import types
import os

# Initialize google-genai client
client = genai.Client()  # Uses env vars automatically

# Define the AI News Agent for ADK
ai_news_agent = LlmAgent(
    name="ai_news_agent",
    model="gemini-1.5-flash",
    description="AI news agent using google-genai SDK",
    instruction="""You are an AI news assistant.
    Provide accurate, up-to-date AI information.
    You are powered by the NEW google-genai SDK.""",
    tools=[]  # Add tools as needed
)

# Required for ADK discovery
root_agent = ai_news_agent

if __name__ == "__main__":
    print(f"Agent '{root_agent.name}' ready!")
    print("Using google-genai SDK (NEW unified SDK)")
    print("Run with: adk web")
"""
}

print(f"üì¶ Deployment Code for: {deployment_type}")
print("Using google-genai SDK (NEW unified SDK)")
print("=" * 60)
print(deployment_code[deployment_type])
print("=" * 60)
print(f"\n‚úÖ Ready to deploy with google-genai SDK!")
print("\nüìù Installation Requirements:")
print("pip install google-genai")
if deployment_type == "Streamlit App":
    print("pip install streamlit")
elif deployment_type == "FastAPI Server":
    print("pip install fastapi uvicorn")
elif deployment_type == "Flask App":
    print("pip install flask")
elif deployment_type == "ADK Web":
    print("pip install google-adk")
print("\n‚ö†Ô∏è Set GEMINI_API_KEY or GOOGLE_API_KEY environment variable")
print("\nüìå Remember: Using google-genai, NOT google-generativeai (deprecated)!")
</file>

<file path="ai_news_chatbot_adk/__init__.py">
"""
AI News Chatbot Agent Package

This package provides a chatbot that can search the web for the latest AI news
and provide informative responses to user queries using Google's Agent Development Kit.

from . import agent: This line performs a relative import, telling Python to look for a module named agent (which corresponds to agent.py) within the current package (personal-assistant). This simple line ensures that when ADK tries to load your personal-assistant agent, it can find and initialize the root_agent defined in agent.py. Even if empty, the presence of __init__.py is what makes the directory a Python package.
"""

from .agent import root_agent

__all__ = ["root_agent"]
</file>

<file path="ai_news_chatbot_adk/agent.py">
"""
AI News Chatbot Agent

This module defines an AI News Agent using Google's Agent Development Kit (ADK).
The agent is designed to search the web for the latest AI news and provide
informative responses to user queries.
"""

from google.adk.agents import LlmAgent
from google.adk.tools import google_search

# Define the model to use
MODEL = "gemini-2.5-flash"

# Create the AI News Agent
ai_news_agent = LlmAgent(
    name="ai_news_agent",
    model=MODEL,
    description="Agent that provides the latest AI news and information",
    instruction="""You are an AI news assistant. Your primary role is to provide accurate,
    up-to-date information about artificial intelligence developments, news, and trends.

    When asked about AI news or developments:
    1. Use the google_search tool to find the most recent and relevant information
    2. Provide concise but informative responses
    3. Include sources or references when appropriate
    4. If the information might be outdated, acknowledge this limitation

    Always maintain a helpful, informative tone and focus on delivering factual information.
    """,
    tools=[google_search]
)

# This is required for ADK to discover the agent
root_agent = ai_news_agent

# For testing the agent directly
if __name__ == "__main__":
    print("AI News Agent created successfully!")
    print(f"Agent name: {root_agent.name}")
    print(f"Agent model: {root_agent.model}")
    print(f"Agent tools: {[type(tool).__name__ for tool in root_agent.tools]}")
</file>

<file path=".env.example">
# Google API Key from Google AI Studio (https://ai.google.dev/)
GOOGLE_API_KEY=your_api_key_here

# Set to FALSE to use Google AI Studio API, or TRUE to use Vertex AI
GOOGLE_GENAI_USE_VERTEXAI=FALSE
</file>

<file path=".repomixignore">
# Add patterns to ignore here, one per line
# Example:
# *.log
# tmp/
</file>

<file path="AI_News_Chatbot_ADK_Tutorial_BACKUP.ipynb">
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ AI News Chatbot with Google Agent Development Kit (ADK)\n",
    "\n",
    "## üéØ Interactive Learning Tutorial\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/ai_news_chatbot_adk/blob/main/AI_News_Chatbot_ADK_Tutorial.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "### üìö **What You'll Learn**\n",
    "\n",
    "1. **Google ADK Fundamentals** - Understanding agents, tools, and orchestration\n",
    "2. **Building AI Agents** - Create your own intelligent assistant\n",
    "3. **Tool Integration** - Connect Google Search and other tools\n",
    "4. **Real-world Application** - Deploy a working AI news assistant\n",
    "5. **Best Practices** - Production-ready patterns and debugging\n",
    "\n",
    "### ‚è±Ô∏è **Estimated Time**: 30-45 minutes\n",
    "\n",
    "### üí° **Prerequisites**: Basic Python knowledge\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Table of Contents\n",
    "\n",
    "1. [Environment Setup](#section1)\n",
    "2. [Understanding ADK Concepts](#section2)\n",
    "3. [Building Your First Agent](#section3)\n",
    "4. [Adding Intelligence with Tools](#section4)\n",
    "5. [Testing Your Agent](#section5)\n",
    "6. [Advanced Features](#section6)\n",
    "7. [Deployment Options](#section7)\n",
    "8. [Exercises & Challenges](#section8)\n",
    "9. [Troubleshooting Guide](#section9)\n",
    "\n",
    "---\n",
    "\n",
    "### üé® **Color Guide**\n",
    "- üü¢ **Run This**: Essential code cells\n",
    "- üîµ **Learn**: Explanations and concepts\n",
    "- üü° **Try This**: Optional experiments\n",
    "- üî¥ **Important**: Critical information\n",
    "- üü£ **Exercise**: Practice challenges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section1\"></a>\n",
    "## 1Ô∏è‚É£ Environment Setup\n",
    "\n",
    "### üîµ **What is Google ADK?**\n",
    "\n",
    "The **Agent Development Kit (ADK)** is Google's framework for building intelligent AI agents that can:\n",
    "- Use tools to interact with the world\n",
    "- Maintain context across conversations\n",
    "- Orchestrate complex tasks\n",
    "- Integrate with Google's AI models (Gemini)\n",
    "\n",
    "Let's start by setting up our environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Installing packages...\n",
      "‚úÖ All packages installed successfully!\n",
      "\n",
      "üì¶ Installed packages:\n",
      "  ‚Ä¢ google-adk\n",
      "  ‚Ä¢ google-generativeai\n",
      "  ‚Ä¢ python-dotenv\n",
      "  ‚Ä¢ ipywidgets\n",
      "  ‚Ä¢ nest-asyncio\n",
      "\n",
      "üéâ Environment ready! Let's build an AI agent!\n"
     ]
    }
   ],
   "source": [
    "#@title üü¢ **Step 1: Install Google ADK and Dependencies** { display-mode: \"form\" }\n",
    "#@markdown Run this cell to install all required packages.\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Install required packages for ADK\"\"\"\n",
    "    packages = [\n",
    "        \"google-adk\",\n",
    "        \"google-generativeai\",\n",
    "        \"python-dotenv\",\n",
    "        \"ipywidgets\",\n",
    "        \"nest-asyncio\"\n",
    "    ]\n",
    "    \n",
    "    print(\"üîß Installing packages...\")\n",
    "    for package in packages:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "    \n",
    "    print(\"‚úÖ All packages installed successfully!\")\n",
    "    print(\"\\nüì¶ Installed packages:\")\n",
    "    for package in packages:\n",
    "        print(f\"  ‚Ä¢ {package}\")\n",
    "\n",
    "install_packages()\n",
    "\n",
    "# Enable nested async for Colab\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"\\nüéâ Environment ready! Let's build an AI agent!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Could not load from Colab Secrets. Please add your key to Secrets or use manual entry.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div style='background-color: #e3f2fd; padding: 15px; border-radius: 5px; margin-top: 10px;'>\n",
       "    <h4>üí° Don't have an API key?</h4>\n",
       "    <ol>\n",
       "        <li>Go to <a href='https://ai.google.dev/' target='_blank'>Google AI Studio</a></li>\n",
       "        <li>Sign in with your Google account</li>\n",
       "        <li>Click \"Get API Key\" ‚Üí \"Create API Key\"</li>\n",
       "        <li>Copy and paste it above</li>\n",
       "    </ol>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title üü¢ **Step 2: Set Up Your Google API Key** { display-mode: \"form\" }\n",
    "#@markdown Enter your Google API key below. Get one free at [Google AI Studio](https://ai.google.dev/)\n",
    "\n",
    "import os\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "import getpass\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Enter your API Key:\n",
    "api_key_method = \"AIzaSyDsr7AV9z3lKLOrHsWa5OepP0b7WMXGtEo\" #@param [\"Enter manually\", \"Use Colab Secrets\"]\n",
    "\n",
    "if api_key_method == \"Enter manually\":\n",
    "    # Create a password input widget\n",
    "    api_key_widget = widgets.Password(\n",
    "        value='',\n",
    "        placeholder='Enter your Google API key',\n",
    "        description='API Key:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    button = widgets.Button(\n",
    "        description='Set API Key',\n",
    "        button_style='success',\n",
    "        icon='check'\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_button_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            if api_key_widget.value:\n",
    "                os.environ['GOOGLE_API_KEY'] = api_key_widget.value\n",
    "                os.environ['GOOGLE_GENAI_USE_VERTEXAI'] = 'FALSE'\n",
    "                print(\"‚úÖ API Key set successfully!\")\n",
    "                print(\"üîí Your key is stored securely for this session.\")\n",
    "                api_key_widget.value = ''  # Clear the input\n",
    "            else:\n",
    "                print(\"‚ùå Please enter a valid API key\")\n",
    "    \n",
    "    button.on_click(on_button_click)\n",
    "    \n",
    "    display(HTML(\"<b>üîê Secure API Key Input:</b>\"))\n",
    "    display(api_key_widget)\n",
    "    display(button)\n",
    "    display(output)\n",
    "    \n",
    "else:\n",
    "    # Use Colab Secrets\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
    "        os.environ['GOOGLE_GENAI_USE_VERTEXAI'] = 'FALSE'\n",
    "        print(\"‚úÖ API Key loaded from Colab Secrets!\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Could not load from Colab Secrets. Please add your key to Secrets or use manual entry.\")\n",
    "\n",
    "# Display helpful information\n",
    "display(HTML(\"\"\"\n",
    "<div style='background-color: #e3f2fd; padding: 15px; border-radius: 5px; margin-top: 10px;'>\n",
    "    <h4>üí° Don't have an API key?</h4>\n",
    "    <ol>\n",
    "        <li>Go to <a href='https://ai.google.dev/' target='_blank'>Google AI Studio</a></li>\n",
    "        <li>Sign in with your Google account</li>\n",
    "        <li>Click \"Get API Key\" ‚Üí \"Create API Key\"</li>\n",
    "        <li>Copy and paste it above</li>\n",
    "    </ol>\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section2\"></a>\n",
    "## 2Ô∏è‚É£ Understanding ADK Concepts\n",
    "\n",
    "### üîµ **Core Components of ADK**\n",
    "\n",
    "Before we build, let's understand the key concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üîµ **Interactive ADK Concepts Explorer** { display-mode: \"form\" }\n",
    "#@markdown Click through the tabs to learn about ADK components\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "html_content = \"\"\"\n",
    "<style>\n",
    ".tab-container {\n",
    "    margin: 20px 0;\n",
    "}\n",
    ".tabs {\n",
    "    display: flex;\n",
    "    border-bottom: 2px solid #ddd;\n",
    "    margin-bottom: 20px;\n",
    "}\n",
    ".tab-button {\n",
    "    padding: 10px 20px;\n",
    "    cursor: pointer;\n",
    "    background: #f5f5f5;\n",
    "    border: none;\n",
    "    border-bottom: 3px solid transparent;\n",
    "    transition: all 0.3s;\n",
    "}\n",
    ".tab-button:hover {\n",
    "    background: #e0e0e0;\n",
    "}\n",
    ".tab-button.active {\n",
    "    background: white;\n",
    "    border-bottom: 3px solid #4285f4;\n",
    "    font-weight: bold;\n",
    "}\n",
    ".tab-content {\n",
    "    padding: 20px;\n",
    "    background: #f9f9f9;\n",
    "    border-radius: 5px;\n",
    "}\n",
    ".concept-card {\n",
    "    background: white;\n",
    "    padding: 15px;\n",
    "    margin: 10px 0;\n",
    "    border-radius: 8px;\n",
    "    box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div class=\"tab-container\">\n",
    "    <div class=\"tabs\">\n",
    "        <button class=\"tab-button active\" onclick=\"showTab('agents')\">ü§ñ Agents</button>\n",
    "        <button class=\"tab-button\" onclick=\"showTab('tools')\">üîß Tools</button>\n",
    "        <button class=\"tab-button\" onclick=\"showTab('models')\">üß† Models</button>\n",
    "        <button class=\"tab-button\" onclick=\"showTab('flows')\">üîÑ Flows</button>\n",
    "    </div>\n",
    "    \n",
    "    <div id=\"agents\" class=\"tab-content\">\n",
    "        <div class=\"concept-card\">\n",
    "            <h3>ü§ñ What are Agents?</h3>\n",
    "            <p>Agents are the core building blocks of ADK. They:</p>\n",
    "            <ul>\n",
    "                <li>Process user inputs and generate responses</li>\n",
    "                <li>Can use tools to perform actions</li>\n",
    "                <li>Maintain context and state</li>\n",
    "                <li>Can be composed together for complex tasks</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <b>Types of Agents:</b>\n",
    "            <ul>\n",
    "                <li><code>LlmAgent</code> - Powered by language models</li>\n",
    "                <li><code>CustomAgent</code> - Custom logic agents</li>\n",
    "                <li><code>WorkflowAgent</code> - Orchestrates other agents</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div id=\"tools\" class=\"tab-content\" style=\"display:none;\">\n",
    "        <div class=\"concept-card\">\n",
    "            <h3>üîß What are Tools?</h3>\n",
    "            <p>Tools extend agent capabilities by allowing them to:</p>\n",
    "            <ul>\n",
    "                <li>Search the web</li>\n",
    "                <li>Access databases</li>\n",
    "                <li>Call APIs</li>\n",
    "                <li>Perform calculations</li>\n",
    "                <li>Interact with external systems</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <b>Built-in Tools:</b>\n",
    "            <ul>\n",
    "                <li><code>google_search</code> - Web search</li>\n",
    "                <li><code>code_execution</code> - Run Python code</li>\n",
    "                <li><code>grounding</code> - Fact verification</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div id=\"models\" class=\"tab-content\" style=\"display:none;\">\n",
    "        <div class=\"concept-card\">\n",
    "            <h3>üß† Supported Models</h3>\n",
    "            <p>ADK works with Google's Gemini family:</p>\n",
    "            <ul>\n",
    "                <li><b>gemini-2.5-flash</b> - Fast, efficient for most tasks</li>\n",
    "                <li><b>gemini-2.5-pro</b> - Advanced reasoning</li>\n",
    "                <li><b>gemini-1.5-flash</b> - Legacy fast model</li>\n",
    "                <li><b>gemini-1.5-pro</b> - Legacy advanced model</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <b>Choosing a Model:</b>\n",
    "            <ul>\n",
    "                <li>Use Flash for: Quick responses, simple tasks</li>\n",
    "                <li>Use Pro for: Complex reasoning, analysis</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div id=\"flows\" class=\"tab-content\" style=\"display:none;\">\n",
    "        <div class=\"concept-card\">\n",
    "            <h3>üîÑ Agent Flows</h3>\n",
    "            <p>Flows control how agents process information:</p>\n",
    "            <ul>\n",
    "                <li><b>Linear Flow</b> - Step-by-step execution</li>\n",
    "                <li><b>Conditional Flow</b> - Based on conditions</li>\n",
    "                <li><b>Loop Flow</b> - Iterative processing</li>\n",
    "                <li><b>Parallel Flow</b> - Concurrent execution</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <b>Flow Components:</b>\n",
    "            <ul>\n",
    "                <li>Input processing</li>\n",
    "                <li>Tool selection</li>\n",
    "                <li>Response generation</li>\n",
    "                <li>Error handling</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<script>\n",
    "function showTab(tabName) {\n",
    "    // Hide all tabs\n",
    "    var tabs = document.getElementsByClassName('tab-content');\n",
    "    for (var i = 0; i < tabs.length; i++) {\n",
    "        tabs[i].style.display = 'none';\n",
    "    }\n",
    "    \n",
    "    // Remove active class from all buttons\n",
    "    var buttons = document.getElementsByClassName('tab-button');\n",
    "    for (var i = 0; i < buttons.length; i++) {\n",
    "        buttons[i].classList.remove('active');\n",
    "    }\n",
    "    \n",
    "    // Show selected tab\n",
    "    document.getElementById(tabName).style.display = 'block';\n",
    "    \n",
    "    // Add active class to clicked button\n",
    "    event.target.classList.add('active');\n",
    "}\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_content))\n",
    "print(\"\\nüìö Explore each tab to understand ADK components!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section3\"></a>\n",
    "## 3Ô∏è‚É£ Building Your First Agent\n",
    "\n",
    "### üîµ **Let's create a simple agent first**\n",
    "\n",
    "We'll start with a basic agent, then add more features progressively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üü¢ **Create a Simple Hello World Agent** { display-mode: \"form\" }\n",
    "#@markdown This is your first ADK agent - it can respond to greetings!\n",
    "\n",
    "from google.adk.agents import LlmAgent\n",
    "import os\n",
    "\n",
    "# Verify API key is set\n",
    "if 'GOOGLE_API_KEY' not in os.environ:\n",
    "    print(\"‚ùå Please set your API key in Step 2 first!\")\n",
    "else:\n",
    "    # Create a simple agent\n",
    "    hello_agent = LlmAgent(\n",
    "        name=\"hello_agent\",\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        description=\"A friendly agent that greets users\",\n",
    "        instruction=\"\"\"You are a friendly assistant. \n",
    "        Greet users warmly and ask how you can help them today.\n",
    "        Keep responses brief and cheerful.\"\"\"\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Simple agent created!\")\n",
    "    print(\"\\nüìã Agent Details:\")\n",
    "    print(f\"  ‚Ä¢ Name: {hello_agent.name}\")\n",
    "    print(f\"  ‚Ä¢ Model: {hello_agent.model}\")\n",
    "    print(f\"  ‚Ä¢ Description: {hello_agent.description}\")\n",
    "    print(\"\\nüéØ Try running the next cell to test it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üü° **Test Your Hello Agent** { display-mode: \"form\" }\n",
    "#@markdown Enter a message to send to your agent\n",
    "\n",
    "test_message = \"Hello!\" #@param {type:\"string\"}\n",
    "\n",
    "if 'hello_agent' in globals():\n",
    "    print(f\"üë§ You: {test_message}\")\n",
    "    print(\"\\nü§ñ Agent is thinking...\\n\")\n",
    "    \n",
    "    # Run the agent\n",
    "    response = hello_agent.run(test_message)\n",
    "    print(f\"ü§ñ Agent: {response}\")\n",
    "else:\n",
    "    print(\"‚ùå Please create the agent first by running the previous cell!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section4\"></a>\n",
    "## 4Ô∏è‚É£ Adding Intelligence with Tools\n",
    "\n",
    "### üîµ **Now let's create our AI News Agent with Google Search**\n",
    "\n",
    "This is where it gets exciting! We'll add the ability to search the web for real-time information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üü¢ **Create the AI News Agent** { display-mode: \"form\" }\n",
    "#@markdown This agent can search the web for the latest AI news!\n",
    "\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools import google_search\n",
    "\n",
    "# Create the AI News Agent with Google Search tool\n",
    "ai_news_agent = LlmAgent(\n",
    "    name=\"ai_news_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    description=\"Agent that provides the latest AI news and information\",\n",
    "    instruction=\"\"\"You are an AI news assistant. Your primary role is to provide accurate, \n",
    "    up-to-date information about artificial intelligence developments, news, and trends.\n",
    "    \n",
    "    When asked about AI news or developments:\n",
    "    1. Use the google_search tool to find the most recent and relevant information\n",
    "    2. Provide concise but informative responses\n",
    "    3. Include sources or references when appropriate\n",
    "    4. If the information might be outdated, acknowledge this limitation\n",
    "    \n",
    "    Always maintain a helpful, informative tone and focus on delivering factual information.\"\"\",\n",
    "    tools=[google_search]  # Adding the Google Search tool\n",
    ")\n",
    "\n",
    "print(\"üéâ AI News Agent created successfully!\")\n",
    "print(\"\\nüîß Agent Configuration:\")\n",
    "print(f\"  ‚Ä¢ Name: {ai_news_agent.name}\")\n",
    "print(f\"  ‚Ä¢ Model: {ai_news_agent.model}\")\n",
    "print(f\"  ‚Ä¢ Tools: Google Search enabled\")\n",
    "print(\"\\nüì∞ This agent can now search for real-time AI news!\")\n",
    "\n",
    "# Store as root_agent for ADK compatibility\n",
    "root_agent = ai_news_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîµ **Understanding How Tools Work**\n",
    "\n",
    "When the agent receives a query about news, it:\n",
    "1. Analyzes the query to understand what information is needed\n",
    "2. Decides if it needs to use the search tool\n",
    "3. Formulates an appropriate search query\n",
    "4. Processes the search results\n",
    "5. Synthesizes a response based on the findings\n",
    "\n",
    "Let's see this in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üü¢ **Interactive AI News Chat Interface** { display-mode: \"form\" }\n",
    "#@markdown Chat with your AI News Agent!\n",
    "\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime\n",
    "\n",
    "# Create chat interface\n",
    "chat_history = []\n",
    "\n",
    "# Create widgets\n",
    "chat_display = widgets.HTML(\n",
    "    value=\"<div style='height:300px; overflow-y:auto; border:1px solid #ddd; padding:10px; background:#f9f9f9;'>\"\n",
    "          \"<p style='color:#666;'>üí¨ Start chatting with your AI News Agent!</p></div>\"\n",
    ")\n",
    "\n",
    "input_box = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your message here...',\n",
    "    description='Message:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "send_button = widgets.Button(\n",
    "    description='Send',\n",
    "    button_style='primary',\n",
    "    icon='paper-plane'\n",
    ")\n",
    "\n",
    "clear_button = widgets.Button(\n",
    "    description='Clear Chat',\n",
    "    button_style='warning',\n",
    "    icon='trash'\n",
    ")\n",
    "\n",
    "status_label = widgets.Label(value=\"Ready to chat!\")\n",
    "\n",
    "# Quick prompts\n",
    "quick_prompts = widgets.ToggleButtons(\n",
    "    options=[\n",
    "        'üì∞ Latest AI News',\n",
    "        'ü§ñ OpenAI Updates',\n",
    "        'üß† Google AI News',\n",
    "        'üî¨ AI Research',\n",
    "        'üíº AI in Business'\n",
    "    ],\n",
    "    description='Quick:',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltips=['Get latest AI news', 'OpenAI updates', 'Google AI news', 'Research breakthroughs', 'Business applications']\n",
    ")\n",
    "\n",
    "def update_chat_display():\n",
    "    \"\"\"Update the chat display with history\"\"\"\n",
    "    html = \"<div style='height:300px; overflow-y:auto; border:1px solid #ddd; padding:10px; background:#f9f9f9;'>\"\n",
    "    \n",
    "    for msg in chat_history:\n",
    "        if msg['role'] == 'user':\n",
    "            html += f\"\"\"<div style='margin:10px 0; text-align:right;'>\n",
    "                        <span style='background:#4285f4; color:white; padding:8px 12px; border-radius:15px; display:inline-block; max-width:70%;'>\n",
    "                        {msg['content']}</span></div>\"\"\"\n",
    "        else:\n",
    "            html += f\"\"\"<div style='margin:10px 0; text-align:left;'>\n",
    "                        <span style='background:#e0e0e0; color:#333; padding:8px 12px; border-radius:15px; display:inline-block; max-width:70%;'>\n",
    "                        {msg['content']}</span></div>\"\"\"\n",
    "    \n",
    "    html += \"</div>\"\n",
    "    chat_display.value = html\n",
    "\n",
    "def send_message(b=None):\n",
    "    \"\"\"Send message to agent\"\"\"\n",
    "    message = input_box.value.strip()\n",
    "    if not message:\n",
    "        return\n",
    "    \n",
    "    # Add user message to history\n",
    "    chat_history.append({'role': 'user', 'content': message})\n",
    "    update_chat_display()\n",
    "    \n",
    "    # Clear input\n",
    "    input_box.value = ''\n",
    "    \n",
    "    # Update status\n",
    "    status_label.value = \"ü§î Agent is thinking...\"\n",
    "    \n",
    "    try:\n",
    "        # Get agent response\n",
    "        response = ai_news_agent.run(message)\n",
    "        \n",
    "        # Add agent response to history\n",
    "        chat_history.append({'role': 'agent', 'content': response})\n",
    "        update_chat_display()\n",
    "        status_label.value = \"‚úÖ Ready to chat!\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        chat_history.append({'role': 'agent', 'content': f\"Sorry, I encountered an error: {str(e)}\"})\n",
    "        update_chat_display()\n",
    "        status_label.value = \"‚ùå Error occurred\"\n",
    "\n",
    "def clear_chat(b):\n",
    "    \"\"\"Clear chat history\"\"\"\n",
    "    global chat_history\n",
    "    chat_history = []\n",
    "    chat_display.value = \"<div style='height:300px; overflow-y:auto; border:1px solid #ddd; padding:10px; background:#f9f9f9;'><p style='color:#666;'>üí¨ Chat cleared. Start a new conversation!</p></div>\"\n",
    "    status_label.value = \"Chat cleared!\"\n",
    "\n",
    "def use_quick_prompt(change):\n",
    "    \"\"\"Use a quick prompt\"\"\"\n",
    "    if change['new']:\n",
    "        prompts_map = {\n",
    "            'üì∞ Latest AI News': \"What are the latest AI news and developments?\",\n",
    "            'ü§ñ OpenAI Updates': \"What's new with OpenAI recently?\",\n",
    "            'üß† Google AI News': \"Tell me about recent Google AI announcements\",\n",
    "            'üî¨ AI Research': \"What are the latest AI research breakthroughs?\",\n",
    "            'üíº AI in Business': \"How is AI being used in business recently?\"\n",
    "        }\n",
    "        input_box.value = prompts_map[change['new']]\n",
    "        quick_prompts.value = None  # Reset selection\n",
    "\n",
    "# Connect event handlers\n",
    "send_button.on_click(send_message)\n",
    "clear_button.on_click(clear_chat)\n",
    "input_box.on_submit(send_message)\n",
    "quick_prompts.observe(use_quick_prompt, names='value')\n",
    "\n",
    "# Display the interface\n",
    "display(HTML(\"<h3>üí¨ AI News Chat Interface</h3>\"))\n",
    "display(quick_prompts)\n",
    "display(chat_display)\n",
    "display(widgets.HBox([input_box, send_button, clear_button]))\n",
    "display(status_label)\n",
    "\n",
    "print(\"\\nüìù Tips:\")\n",
    "print(\"  ‚Ä¢ Use quick prompts for common queries\")\n",
    "print(\"  ‚Ä¢ Press Enter or click Send to submit\")\n",
    "print(\"  ‚Ä¢ The agent will search the web for real-time information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section5\"></a>\n",
    "## 5Ô∏è‚É£ Testing Your Agent\n",
    "\n",
    "### üîµ **Let's test different types of queries**\n",
    "\n",
    "Try these different query types to understand how your agent works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üü° **Agent Testing Suite** { display-mode: \"form\" }\n",
    "#@markdown Test your agent with different query types\n",
    "\n",
    "test_queries = [\n",
    "    {\"type\": \"Recent News\", \"query\": \"What happened in AI this week?\"},\n",
    "    {\"type\": \"Company Updates\", \"query\": \"Latest news about OpenAI\"},\n",
    "    {\"type\": \"Technical\", \"query\": \"What is a transformer model?\"},\n",
    "    {\"type\": \"Trends\", \"query\": \"What are the AI trends for 2024?\"},\n",
    "    {\"type\": \"Ethics\", \"query\": \"Recent AI ethics concerns\"}\n",
    "]\n",
    "\n",
    "query_type = \"Recent News\" #@param [\"Recent News\", \"Company Updates\", \"Technical\", \"Trends\", \"Ethics\"]\n",
    "run_test = True #@param {type:\"boolean\"}\n",
    "\n",
    "if run_test and 'ai_news_agent' in globals():\n",
    "    selected_query = next(q for q in test_queries if q[\"type\"] == query_type)\n",
    "    \n",
    "    print(f\"üß™ Testing Query Type: {selected_query['type']}\")\n",
    "    print(f\"üìù Query: {selected_query['query']}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    print(\"‚è≥ Processing...\\n\")\n",
    "    \n",
    "    try:\n",
    "        response = ai_news_agent.run(selected_query['query'])\n",
    "        print(\"ü§ñ Agent Response:\")\n",
    "        print(\"\\n\" + response)\n",
    "        \n",
    "        # Analyze the response\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"\\nüìä Response Analysis:\")\n",
    "        print(f\"  ‚Ä¢ Length: {len(response.split())} words\")\n",
    "        print(f\"  ‚Ä¢ Has sources: {'Yes' if 'http' in response or 'source' in response.lower() else 'No'}\")\n",
    "        print(f\"  ‚Ä¢ Mentions dates: {'Yes' if any(str(y) in response for y in range(2020, 2026)) else 'No'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "        print(\"\\nüí° Tip: Make sure your API key is set correctly\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Set run_test to True and select a query type to test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section6\"></a>\n",
    "## 6Ô∏è‚É£ Advanced Features\n",
    "\n",
    "### üîµ **Let's explore advanced ADK features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üü° **Create a Multi-Tool Agent** { display-mode: \"form\" }\n",
    "#@markdown This agent has multiple capabilities!\n",
    "\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools import google_search\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Create a custom tool function\n",
    "def calculate_reading_time(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"Calculate estimated reading time for text\"\"\"\n",
    "    words = len(text.split())\n",
    "    reading_speed = 200  # words per minute\n",
    "    minutes = words / reading_speed\n",
    "    \n",
    "    return {\n",
    "        \"words\": words,\n",
    "        \"estimated_minutes\": round(minutes, 1),\n",
    "        \"difficulty\": \"Easy\" if words < 500 else \"Medium\" if words < 1000 else \"Long\"\n",
    "    }\n",
    "\n",
    "# Create an advanced agent with multiple tools\n",
    "advanced_agent = LlmAgent(\n",
    "    name=\"advanced_news_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    description=\"Advanced AI news agent with analysis capabilities\",\n",
    "    instruction=\"\"\"You are an advanced AI news analyst. You can:\n",
    "    1. Search for the latest AI news using google_search\n",
    "    2. Provide detailed analysis of trends\n",
    "    3. Summarize complex topics clearly\n",
    "    4. Compare different AI developments\n",
    "    \n",
    "    When providing news:\n",
    "    - Include context and background\n",
    "    - Highlight key implications\n",
    "    - Mention relevant companies or researchers\n",
    "    - Provide balanced perspectives\"\"\",\n",
    "    tools=[google_search]  # Add more tools as needed\n",
    ")\n",
    "\n",
    "print(\"üöÄ Advanced agent created!\")\n",
    "print(\"\\nüéØ Advanced Capabilities:\")\n",
    "print(\"  ‚Ä¢ Web search for real-time information\")\n",
    "print(\"  ‚Ä¢ Trend analysis\")\n",
    "print(\"  ‚Ä¢ Comparative analysis\")\n",
    "print(\"  ‚Ä¢ Context-aware responses\")\n",
    "print(\"\\nüí° Try asking for comparisons or analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üü° **Agent with Memory (Session Management)** { display-mode: \"form\" }\n",
    "#@markdown Create an agent that remembers previous conversations\n",
    "\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools import google_search\n",
    "from typing import List, Dict\n",
    "\n",
    "class ConversationMemory:\n",
    "    \"\"\"Simple conversation memory manager\"\"\"\n",
    "    def __init__(self):\n",
    "        self.history: List[Dict[str, str]] = []\n",
    "        self.topics: set = set()\n",
    "    \n",
    "    def add_exchange(self, user_msg: str, agent_response: str):\n",
    "        \"\"\"Add a conversation exchange\"\"\"\n",
    "        self.history.append({\n",
    "            \"user\": user_msg,\n",
    "            \"agent\": agent_response\n",
    "        })\n",
    "        # Extract topics (simple keyword extraction)\n",
    "        keywords = [word.lower() for word in user_msg.split() if len(word) > 4]\n",
    "        self.topics.update(keywords)\n",
    "    \n",
    "    def get_context(self, max_exchanges: int = 3) -> str:\n",
    "        \"\"\"Get conversation context\"\"\"\n",
    "        if not self.history:\n",
    "            return \"No previous conversation.\"\n",
    "        \n",
    "        recent = self.history[-max_exchanges:]\n",
    "        context = \"Previous conversation:\\n\"\n",
    "        for exchange in recent:\n",
    "            context += f\"User: {exchange['user']}\\n\"\n",
    "            context += f\"Agent: {exchange['agent'][:100]}...\\n\"\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def get_topics(self) -> List[str]:\n",
    "        \"\"\"Get discussed topics\"\"\"\n",
    "        return list(self.topics)\n",
    "\n",
    "# Initialize memory\n",
    "conversation_memory = ConversationMemory()\n",
    "\n",
    "# Create agent with memory context\n",
    "memory_agent = LlmAgent(\n",
    "    name=\"memory_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    description=\"AI news agent with conversation memory\",\n",
    "    instruction=\"\"\"You are an AI news assistant with memory of our conversation.\n",
    "    Remember what we've discussed and build upon previous topics.\n",
    "    Reference earlier parts of our conversation when relevant.\"\"\",\n",
    "    tools=[google_search]\n",
    ")\n",
    "\n",
    "def chat_with_memory(message: str) -> str:\n",
    "    \"\"\"Chat with the agent while maintaining memory\"\"\"\n",
    "    # Add context from memory\n",
    "    context = conversation_memory.get_context()\n",
    "    full_prompt = f\"{context}\\n\\nCurrent question: {message}\"\n",
    "    \n",
    "    # Get response\n",
    "    response = memory_agent.run(full_prompt)\n",
    "    \n",
    "    # Store in memory\n",
    "    conversation_memory.add_exchange(message, response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"üß† Agent with memory created!\")\n",
    "print(\"\\nüìù Memory Features:\")\n",
    "print(\"  ‚Ä¢ Remembers conversation history\")\n",
    "print(\"  ‚Ä¢ Tracks discussed topics\")\n",
    "print(\"  ‚Ä¢ Provides contextual responses\")\n",
    "print(\"  ‚Ä¢ Builds on previous discussions\")\n",
    "print(\"\\nüí¨ Try having a multi-turn conversation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section7\"></a>\n",
    "## 7Ô∏è‚É£ Deployment Options\n",
    "\n",
    "### üîµ **How to Deploy Your Agent**\n",
    "\n",
    "Your agent can be deployed in several ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üîµ **Export Your Agent for Deployment** { display-mode: \"form\" }\n",
    "#@markdown Generate deployment-ready code for your agent\n",
    "\n",
    "deployment_type = \"Local ADK Web\" #@param [\"Local ADK Web\", \"Cloud Run\", \"Streamlit App\", \"FastAPI Server\"]\n",
    "\n",
    "deployment_code = {\n",
    "    \"Local ADK Web\": \"\"\"# agent.py\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools import google_search\n",
    "\n",
    "# Define the AI News Agent\n",
    "ai_news_agent = LlmAgent(\n",
    "    name=\"ai_news_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    description=\"Agent that provides the latest AI news and information\",\n",
    "    instruction=\"\"\"You are an AI news assistant...\"\"\",\n",
    "    tools=[google_search]\n",
    ")\n",
    "\n",
    "# Required for ADK discovery\n",
    "root_agent = ai_news_agent\n",
    "\n",
    "# Run with: adk web\n",
    "\"\"\",\n",
    "    \n",
    "    \"Cloud Run\": \"\"\"# main.py\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools import google_search\n",
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "agent = LlmAgent(\n",
    "    name=\"ai_news_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    description=\"AI news agent\",\n",
    "    instruction=\"...your instructions...\",\n",
    "    tools=[google_search]\n",
    ")\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "async def chat(message: str):\n",
    "    response = agent.run(message)\n",
    "    return {\"response\": response}\n",
    "\n",
    "# Dockerfile\n",
    "FROM python:3.12\n",
    "WORKDIR /app\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "COPY . .\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "\"\"\",\n",
    "    \n",
    "    \"Streamlit App\": \"\"\"# app.py\n",
    "import streamlit as st\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools import google_search\n",
    "\n",
    "# Initialize agent\n",
    "@st.cache_resource\n",
    "def get_agent():\n",
    "    return LlmAgent(\n",
    "        name=\"ai_news_agent\",\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        description=\"AI news agent\",\n",
    "        instruction=\"...your instructions...\",\n",
    "        tools=[google_search]\n",
    "    )\n",
    "\n",
    "agent = get_agent()\n",
    "\n",
    "st.title(\"ü§ñ AI News Chatbot\")\n",
    "\n",
    "# Chat interface\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "if prompt := st.chat_input(\"Ask about AI news...\"):\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "    \n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Searching...\"):\n",
    "            response = agent.run(prompt)\n",
    "        st.markdown(response)\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "# Run with: streamlit run app.py\n",
    "\"\"\",\n",
    "    \n",
    "    \"FastAPI Server\": \"\"\"# server.py\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.tools import google_search\n",
    "import uvicorn\n",
    "\n",
    "app = FastAPI(title=\"AI News API\")\n",
    "\n",
    "class ChatRequest(BaseModel):\n",
    "    message: str\n",
    "    session_id: str = \"default\"\n",
    "\n",
    "class ChatResponse(BaseModel):\n",
    "    response: str\n",
    "    session_id: str\n",
    "\n",
    "# Initialize agent\n",
    "agent = LlmAgent(\n",
    "    name=\"ai_news_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    description=\"AI news agent\",\n",
    "    instruction=\"...your instructions...\",\n",
    "    tools=[google_search]\n",
    ")\n",
    "\n",
    "@app.post(\"/chat\", response_model=ChatResponse)\n",
    "async def chat(request: ChatRequest):\n",
    "    try:\n",
    "        response = agent.run(request.message)\n",
    "        return ChatResponse(\n",
    "            response=response,\n",
    "            session_id=request.session_id\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health():\n",
    "    return {\"status\": \"healthy\"}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "# Run with: python server.py\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "print(f\"üì¶ Deployment Code for: {deployment_type}\")\n",
    "print(\"=\"*50)\n",
    "print(deployment_code[deployment_type])\n",
    "print(\"=\"*50)\n",
    "print(\"\\nüìù Next Steps:\")\n",
    "\n",
    "if deployment_type == \"Local ADK Web\":\n",
    "    print(\"1. Save the code as 'agent.py'\")\n",
    "    print(\"2. Create a .env file with your API key\")\n",
    "    print(\"3. Run: adk web\")\n",
    "    print(\"4. Access at http://localhost:8000\")\n",
    "elif deployment_type == \"Cloud Run\":\n",
    "    print(\"1. Create the files shown above\")\n",
    "    print(\"2. Build Docker image: docker build -t ai-news-agent .\")\n",
    "    print(\"3. Deploy to Cloud Run via Console or CLI\")\n",
    "    print(\"4. Set environment variables in Cloud Run\")\n",
    "elif deployment_type == \"Streamlit App\":\n",
    "    print(\"1. Save the code as 'app.py'\")\n",
    "    print(\"2. Install: pip install streamlit google-adk\")\n",
    "    print(\"3. Set GOOGLE_API_KEY environment variable\")\n",
    "    print(\"4. Run: streamlit run app.py\")\n",
    "else:\n",
    "    print(\"1. Save the code as 'server.py'\")\n",
    "    print(\"2. Install: pip install fastapi uvicorn google-adk\")\n",
    "    print(\"3. Set GOOGLE_API_KEY environment variable\")\n",
    "    print(\"4. Run: python server.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section8\"></a>\n",
    "## 8Ô∏è‚É£ Exercises & Challenges\n",
    "\n",
    "### üü£ **Practice Exercises**\n",
    "\n",
    "Test your understanding with these challenges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üü£ **Exercise 1: Customize Your Agent** { display-mode: \"form\" }\n",
    "#@markdown Modify the agent to focus on a specific AI topic\n",
    "\n",
    "specialization = \"AI in Healthcare\" #@param [\"AI in Healthcare\", \"AI Ethics\", \"AI Startups\", \"AI Research Papers\", \"AI Job Market\"]\n",
    "\n",
    "# Exercise: Create a specialized agent\n",
    "exercise_instructions = {\n",
    "    \"AI in Healthcare\": \"\"\"Create an agent specialized in healthcare AI:\n",
    "    - Focus on medical AI applications\n",
    "    - Include FDA approvals and clinical trials\n",
    "    - Mention patient privacy considerations\"\"\",\n",
    "    \n",
    "    \"AI Ethics\": \"\"\"Create an agent focused on AI ethics:\n",
    "    - Discuss bias and fairness\n",
    "    - Include regulatory updates\n",
    "    - Cover responsible AI practices\"\"\",\n",
    "    \n",
    "    \"AI Startups\": \"\"\"Create an agent for AI startup news:\n",
    "    - Track funding rounds\n",
    "    - Cover new AI companies\n",
    "    - Include acquisition news\"\"\",\n",
    "    \n",
    "    \"AI Research Papers\": \"\"\"Create an agent for academic AI:\n",
    "    - Summarize recent papers\n",
    "    - Explain technical concepts\n",
    "    - Track conference announcements\"\"\",\n",
    "    \n",
    "    \"AI Job Market\": \"\"\"Create an agent for AI careers:\n",
    "    - Track job trends\n",
    "    - Required skills updates\n",
    "    - Salary information\"\"\"\n",
    "}\n",
    "\n",
    "print(f\"üéØ Exercise: Create a {specialization} Agent\")\n",
    "print(\"\\nüìã Requirements:\")\n",
    "print(exercise_instructions[specialization])\n",
    "print(\"\\nüíª Your Code Template:\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "code_template = f\"\"\"from google.adk.agents import LlmAgent\n",
    "from google.adk.tools import google_search\n",
    "\n",
    "# TODO: Customize this agent for {specialization}\n",
    "specialized_agent = LlmAgent(\n",
    "    name=\"{specialization.lower().replace(' ', '_')}_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    description=\"Agent specialized in {specialization}\",\n",
    "    instruction=\"\"\"TODO: Write instructions for {specialization} focus.\n",
    "    Include:\n",
    "    1. Specific topics to cover\n",
    "    2. Types of sources to prioritize\n",
    "    3. Key information to extract\n",
    "    4. How to format responses\n",
    "    \"\"\",\n",
    "    tools=[google_search]\n",
    ")\n",
    "\n",
    "# Test your agent\n",
    "test_query = \"TODO: Write a test query for {specialization}\"\n",
    "response = specialized_agent.run(test_query)\n",
    "print(response)\n",
    "\"\"\"\n",
    "\n",
    "print(code_template)\n",
    "print(\"-\"*50)\n",
    "print(\"\\n‚úèÔ∏è Modify the code above and run it in the next cell!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üü£ Your exercise code here:\n",
    "# Copy and modify the template from above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üü£ **Exercise 2: Multi-Agent System** { display-mode: \"form\" }\n",
    "#@markdown Create a system with multiple specialized agents\n",
    "\n",
    "print(\"üéØ Challenge: Create a Multi-Agent News System\")\n",
    "print(\"\\nüìã Requirements:\")\n",
    "print(\"1. Create 3 different specialized agents\")\n",
    "print(\"2. One coordinator agent to route queries\")\n",
    "print(\"3. Each agent should have unique expertise\")\n",
    "print(\"\\nüíª Starter Code:\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "starter_code = \"\"\"from google.adk.agents import LlmAgent\n",
    "from google.adk.tools import google_search\n",
    "\n",
    "# Agent 1: Breaking News\n",
    "breaking_news_agent = LlmAgent(\n",
    "    name=\"breaking_news\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    description=\"Focuses on latest breaking AI news\",\n",
    "    instruction=\"Find the most recent AI news from the last 24 hours\",\n",
    "    tools=[google_search]\n",
    ")\n",
    "\n",
    "# Agent 2: Technical Analysis\n",
    "technical_agent = LlmAgent(\n",
    "    name=\"technical_analyst\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    description=\"Provides technical analysis of AI developments\",\n",
    "    instruction=\"Explain technical aspects and implications of AI news\",\n",
    "    tools=[google_search]\n",
    ")\n",
    "\n",
    "# TODO: Add Agent 3 - Your choice!\n",
    "# custom_agent = LlmAgent(...)\n",
    "\n",
    "# Coordinator Agent\n",
    "def route_query(query: str):\n",
    "    \"\"\"Route query to appropriate agent\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    if \"breaking\" in query_lower or \"latest\" in query_lower:\n",
    "        return breaking_news_agent.run(query)\n",
    "    elif \"technical\" in query_lower or \"how\" in query_lower:\n",
    "        return technical_agent.run(query)\n",
    "    else:\n",
    "        # TODO: Add routing for your custom agent\n",
    "        return \"Please specify the type of information you need.\"\n",
    "\n",
    "# Test the system\n",
    "test_queries = [\n",
    "    \"What's the latest breaking AI news?\",\n",
    "    \"Explain technical details of transformers\",\n",
    "    # TODO: Add test for your custom agent\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"Q: {query}\")\n",
    "    print(f\"A: {route_query(query)[:200]}...\\n\")\n",
    "\"\"\"\n",
    "\n",
    "print(starter_code)\n",
    "print(\"-\"*50)\n",
    "print(\"\\n‚úèÔ∏è Complete the TODO sections and test your multi-agent system!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section9\"></a>\n",
    "## 9Ô∏è‚É£ Troubleshooting Guide\n",
    "\n",
    "### üî¥ **Common Issues and Solutions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üî¥ **Interactive Troubleshooting Helper** { display-mode: \"form\" }\n",
    "#@markdown Select your issue to see the solution\n",
    "\n",
    "issue = \"API Key Error\" #@param [\"API Key Error\", \"Import Error\", \"Agent Not Responding\", \"Tool Not Working\", \"Memory Error\", \"Timeout Error\"]\n",
    "\n",
    "solutions = {\n",
    "    \"API Key Error\": {\n",
    "        \"symptoms\": \"Error messages about invalid or missing API key\",\n",
    "        \"causes\": [\n",
    "            \"API key not set in environment\",\n",
    "            \"Invalid or expired API key\",\n",
    "            \"Incorrect environment variable name\"\n",
    "        ],\n",
    "        \"solutions\": [\n",
    "            \"1. Verify API key is set: print(os.environ.get('GOOGLE_API_KEY', 'Not set'))\",\n",
    "            \"2. Get a new key from https://ai.google.dev/\",\n",
    "            \"3. Set correctly: os.environ['GOOGLE_API_KEY'] = 'your-key'\",\n",
    "            \"4. Restart runtime after setting key\"\n",
    "        ],\n",
    "        \"test_code\": \"\"\"import os\n",
    "# Check if API key is set\n",
    "if 'GOOGLE_API_KEY' in os.environ:\n",
    "    print(\"‚úÖ API key is set\")\n",
    "    print(f\"Key starts with: {os.environ['GOOGLE_API_KEY'][:10]}...\")\n",
    "else:\n",
    "    print(\"‚ùå API key not found in environment\")\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"Import Error\": {\n",
    "        \"symptoms\": \"ModuleNotFoundError or ImportError\",\n",
    "        \"causes\": [\n",
    "            \"Package not installed\",\n",
    "            \"Wrong package version\",\n",
    "            \"Runtime needs restart\"\n",
    "        ],\n",
    "        \"solutions\": [\n",
    "            \"1. Install missing package: !pip install google-adk\",\n",
    "            \"2. Upgrade to latest: !pip install --upgrade google-adk\",\n",
    "            \"3. Restart runtime: Runtime ‚Üí Restart runtime\",\n",
    "            \"4. Check installed packages: !pip list | grep google\"\n",
    "        ],\n",
    "        \"test_code\": \"\"\"# Check ADK installation\n",
    "try:\n",
    "    import google.adk\n",
    "    print(f\"‚úÖ ADK version: {google.adk.__version__ if hasattr(google.adk, '__version__') else 'Unknown'}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå ADK not installed: {e}\")\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"Agent Not Responding\": {\n",
    "        \"symptoms\": \"Agent hangs or returns empty responses\",\n",
    "        \"causes\": [\n",
    "            \"Network connectivity issues\",\n",
    "            \"Model overloaded\",\n",
    "            \"Instruction too complex\"\n",
    "        ],\n",
    "        \"solutions\": [\n",
    "            \"1. Simplify agent instructions\",\n",
    "            \"2. Use gemini-2.5-flash for faster responses\",\n",
    "            \"3. Add timeout handling\",\n",
    "            \"4. Check network: !ping google.com -c 3\"\n",
    "        ],\n",
    "        \"test_code\": \"\"\"# Test basic agent response\n",
    "from google.adk.agents import LlmAgent\n",
    "\n",
    "test_agent = LlmAgent(\n",
    "    name=\"test\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    description=\"Test agent\",\n",
    "    instruction=\"Simply say hello\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = test_agent.run(\"Hi\")\n",
    "    print(f\"‚úÖ Agent responded: {response[:50]}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Agent error: {e}\")\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"Tool Not Working\": {\n",
    "        \"symptoms\": \"Google Search or other tools not functioning\",\n",
    "        \"causes\": [\n",
    "            \"Tool not properly imported\",\n",
    "            \"API restrictions\",\n",
    "            \"Tool not added to agent\"\n",
    "        ],\n",
    "        \"solutions\": [\n",
    "            \"1. Verify tool import: from google.adk.tools import google_search\",\n",
    "            \"2. Add tool to agent: tools=[google_search]\",\n",
    "            \"3. Check API quotas\",\n",
    "            \"4. Try without tools first\"\n",
    "        ],\n",
    "        \"test_code\": \"\"\"# Test tool availability\n",
    "from google.adk.tools import google_search\n",
    "\n",
    "print(f\"‚úÖ Google Search tool imported: {google_search}\")\n",
    "print(f\"Tool type: {type(google_search)}\")\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"Memory Error\": {\n",
    "        \"symptoms\": \"Out of memory or Colab crashes\",\n",
    "        \"causes\": [\n",
    "            \"Long conversation history\",\n",
    "            \"Large responses cached\",\n",
    "            \"Memory leak in loop\"\n",
    "        ],\n",
    "        \"solutions\": [\n",
    "            \"1. Clear variables: del large_variable\",\n",
    "            \"2. Garbage collect: import gc; gc.collect()\",\n",
    "            \"3. Limit history size\",\n",
    "            \"4. Restart runtime if needed\"\n",
    "        ],\n",
    "        \"test_code\": \"\"\"# Check memory usage\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "mem_info = process.memory_info()\n",
    "print(f\"Memory used: {mem_info.rss / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Available: {psutil.virtual_memory().available / 1024 / 1024:.2f} MB\")\"\"\"\n",
    "    },\n",
    "    \n",
    "    \"Timeout Error\": {\n",
    "        \"symptoms\": \"Request timeout or deadline exceeded\",\n",
    "        \"causes\": [\n",
    "            \"Slow network connection\",\n",
    "            \"Complex query requiring long processing\",\n",
    "            \"API rate limits\"\n",
    "        ],\n",
    "        \"solutions\": [\n",
    "            \"1. Simplify queries\",\n",
    "            \"2. Implement retry logic\",\n",
    "            \"3. Use async execution\",\n",
    "            \"4. Check API status: https://status.cloud.google.com/\"\n",
    "        ],\n",
    "        \"test_code\": \"\"\"# Test with timeout handling\n",
    "import asyncio\n",
    "from google.adk.agents import LlmAgent\n",
    "\n",
    "async def test_with_timeout():\n",
    "    agent = LlmAgent(\n",
    "        name=\"test\",\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        description=\"Test\",\n",
    "        instruction=\"Be brief\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        response = await asyncio.wait_for(\n",
    "            asyncio.create_task(agent.run(\"Hi\")),\n",
    "            timeout=10.0\n",
    "        )\n",
    "        print(\"‚úÖ Response received within timeout\")\n",
    "    except asyncio.TimeoutError:\n",
    "        print(\"‚ùå Request timed out\")\n",
    "\n",
    "# Run test\n",
    "await test_with_timeout()\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "selected_solution = solutions[issue]\n",
    "\n",
    "print(f\"üîß Troubleshooting: {issue}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nüîç Symptoms: {selected_solution['symptoms']}\")\n",
    "print(\"\\n‚ùì Common Causes:\")\n",
    "for cause in selected_solution['causes']:\n",
    "    print(f\"  ‚Ä¢ {cause}\")\n",
    "\n",
    "print(\"\\n‚úÖ Solutions:\")\n",
    "for solution in selected_solution['solutions']:\n",
    "    print(f\"  {solution}\")\n",
    "\n",
    "print(\"\\nüíª Test Code:\")\n",
    "print(\"-\"*50)\n",
    "print(selected_solution['test_code'])\n",
    "print(\"-\"*50)\n",
    "print(\"\\nüìù Copy and run the test code above to diagnose the issue.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "You've completed the **AI News Chatbot ADK Tutorial**! \n",
    "\n",
    "### üìö What You've Learned:\n",
    "- ‚úÖ Setting up Google ADK environment\n",
    "- ‚úÖ Creating intelligent agents with LLMs\n",
    "- ‚úÖ Integrating tools like Google Search\n",
    "- ‚úÖ Building interactive chat interfaces\n",
    "- ‚úÖ Advanced features like memory and multi-agent systems\n",
    "- ‚úÖ Deployment strategies for production\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "1. **Customize** your agent for specific use cases\n",
    "2. **Add more tools** from the ADK toolkit\n",
    "3. **Deploy** your agent to Cloud Run or other platforms\n",
    "4. **Share** your creation with others!\n",
    "\n",
    "### üîó Resources:\n",
    "- [Google ADK Documentation](https://google.github.io/adk-docs/)\n",
    "- [ADK GitHub Samples](https://github.com/google/adk-samples)\n",
    "- [Google AI Studio](https://ai.google.dev/)\n",
    "- [Gemini API Documentation](https://ai.google.dev/docs)\n",
    "\n",
    "### üí¨ Feedback:\n",
    "If you found this tutorial helpful, please:\n",
    "- ‚≠ê Star the repository\n",
    "- üîÄ Share with others learning ADK\n",
    "- üí° Contribute improvements\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Building with ADK!** ü§ñ‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title üéì **Generate Your Completion Certificate** { display-mode: \"form\" }\n",
    "#@markdown Enter your name to generate a certificate!\n",
    "\n",
    "your_name = \"Your Name\" #@param {type:\"string\"}\n",
    "completion_date = \"2024\" #@param {type:\"string\"}\n",
    "\n",
    "from IPython.display import HTML\n",
    "import datetime\n",
    "\n",
    "if your_name != \"Your Name\":\n",
    "    certificate_html = f\"\"\"\n",
    "    <div style=\"\n",
    "        border: 5px solid #4285f4;\n",
    "        padding: 40px;\n",
    "        text-align: center;\n",
    "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "        color: white;\n",
    "        border-radius: 20px;\n",
    "        box-shadow: 0 10px 30px rgba(0,0,0,0.3);\n",
    "        max-width: 600px;\n",
    "        margin: 20px auto;\n",
    "    \">\n",
    "        <h1 style=\"font-size: 2.5em; margin-bottom: 20px;\">üéì Certificate of Completion</h1>\n",
    "        <p style=\"font-size: 1.2em;\">This certifies that</p>\n",
    "        <h2 style=\"font-size: 2em; margin: 20px 0; text-decoration: underline;\">{your_name}</h2>\n",
    "        <p style=\"font-size: 1.2em;\">has successfully completed the</p>\n",
    "        <h3 style=\"font-size: 1.5em; margin: 20px 0;\">AI News Chatbot with Google ADK</h3>\n",
    "        <p style=\"font-size: 1.1em;\">Interactive Learning Tutorial</p>\n",
    "        <p style=\"margin-top: 30px; font-size: 1em;\">Completed on: {completion_date}</p>\n",
    "        <div style=\"margin-top: 30px;\">\n",
    "            <span style=\"font-size: 2em;\">ü§ñ</span>\n",
    "            <span style=\"font-size: 2em;\">üéØ</span>\n",
    "            <span style=\"font-size: 2em;\">‚ú®</span>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(certificate_html))\n",
    "    print(\"\\nüéä Congratulations on completing the tutorial!\")\n",
    "    print(\"üì∏ Take a screenshot of your certificate to share!\")\n",
    "else:\n",
    "    print(\"üìù Please enter your name above to generate your certificate!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
</file>

<file path="AI_News_Chatbot_ADK_Tutorial.ipynb">
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ AI News Chatbot with Google Agent Development Kit (ADK)\n",
    "\n",
    "## üéØ Interactive Learning Tutorial - Updated with NEW google-genai SDK\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/ai_news_chatbot_adk/blob/main/AI_News_Chatbot_ADK_Tutorial.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "### üìö **What You'll Learn**\n",
    "\n",
    "1. **Google ADK Fundamentals** - Understanding agents, tools, and orchestration\n",
    "2. **NEW google-genai SDK** - Using the modern unified SDK (NOT google-generativeai)\n",
    "3. **Building AI Agents** - Create your own intelligent assistant\n",
    "4. **Tool Integration** - Connect Google Search and other tools\n",
    "5. **Real-world Application** - Deploy a working AI news assistant\n",
    "6. **Best Practices** - Production-ready patterns and debugging\n",
    "\n",
    "### ‚è±Ô∏è **Estimated Time**: 30-45 minutes\n",
    "\n",
    "### üí° **Prerequisites**: Basic Python knowledge\n",
    "\n",
    "### üÜï **Updated**: Using google-genai (the new unified SDK, NOT the deprecated google-generativeai)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Table of Contents\n",
    "\n",
    "1. [Environment Setup](#section1)\n",
    "2. [Understanding ADK Concepts](#section2)\n",
    "3. [Building Your First Agent](#section3)\n",
    "4. [Adding Intelligence with Tools](#section4)\n",
    "5. [Testing Your Agent](#section5)\n",
    "6. [Advanced Features](#section6)\n",
    "7. [Deployment Options](#section7)\n",
    "8. [Exercises & Challenges](#section8)\n",
    "9. [Troubleshooting Guide](#section9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section1\"></a>\n",
    "## 1Ô∏è‚É£ Environment Setup\n",
    "\n",
    "### üîµ **What is Google ADK?**\n",
    "\n",
    "The **Agent Development Kit (ADK)** is Google's framework for building intelligent AI agents.\n",
    "\n",
    "### üîµ **What is google-genai?**\n",
    "\n",
    "The **google-genai** is the NEW unified Google Gen AI SDK that replaces google-generativeai. It provides a unified interface for both Google AI and Vertex AI.\n",
    "\n",
    "Let's start by setting up our environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üü¢ **Step 1: Install Google ADK and NEW google-genai SDK** { display-mode: \"form\" }\n",
    "#@markdown Run this cell to install all required packages.\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Install required packages for ADK with NEW google-genai SDK\"\"\"\n",
    "    packages = [\n",
    "        \"google-genai\",          # NEW unified Google Gen AI SDK (replaces google-generativeai)\n",
    "        \"google-adk\",            # ADK package\n",
    "        \"python-dotenv>=1.0.0\",\n",
    "        \"ipywidgets>=8.0.0\",\n",
    "        \"nest-asyncio>=1.5.0\"\n",
    "    ]\n",
    "    \n",
    "    print(\"üîß Installing packages...\")\n",
    "    print(\"üìå NOTE: Installing google-genai (NEW), NOT google-generativeai (deprecated)\\n\")\n",
    "    \n",
    "    for package in packages:\n",
    "        print(f\"  Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "    \n",
    "    print(\"\\n‚úÖ All packages installed successfully!\")\n",
    "    print(\"\\nüì¶ Installed packages:\")\n",
    "    for package in packages:\n",
    "        print(f\"  ‚Ä¢ {package}\")\n",
    "    print(\"\\nüÜï Using google-genai - the new unified SDK\")\n",
    "\n",
    "install_packages()\n",
    "\n",
    "# Enable nested async for Colab\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"\\nüéâ Environment ready with NEW google-genai SDK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üü¢ **Step 2: Set Up Your Google API Key** { display-mode: \"form\" }\n",
    "#@markdown Enter your Google API key below. Get one free at [Google AI Studio](https://ai.google.dev/)\n",
    "\n",
    "import os\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Set API key\n",
    "API_KEY = 'AIzaSyDsr7AV9z3lKLOrHsWa5OepP0b7WMXGtEo'  # Your API key\n",
    "\n",
    "# Set environment variables - google-genai automatically uses these\n",
    "os.environ['GEMINI_API_KEY'] = API_KEY  # Primary env var for new SDK\n",
    "os.environ['GOOGLE_API_KEY'] = API_KEY  # Fallback env var\n",
    "\n",
    "print(\"‚úÖ API Key set successfully!\")\n",
    "print(\"üîí Your key is stored securely for this session.\")\n",
    "\n",
    "# Test the NEW google-genai SDK\n",
    "print(\"\\nüß™ Testing google-genai SDK...\")\n",
    "try:\n",
    "    from google import genai\n",
    "    from google.genai import types\n",
    "    \n",
    "    # Create client - automatically uses GEMINI_API_KEY or GOOGLE_API_KEY\n",
    "    client = genai.Client()  # No need to pass API key, uses env vars\n",
    "    \n",
    "    # Test with simple generation\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-1.5-flash',\n",
    "        contents='Say \"API configured successfully\" in exactly 3 words'\n",
    "    )\n",
    "    print(f\"‚úÖ Test response: {response.text}\")\n",
    "    print(\"‚úÖ google-genai SDK is working correctly!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error: {e}\")\n",
    "    print(\"Please check your API key and try again\")\n",
    "\n",
    "# Display helpful information\n",
    "display(HTML(\"\"\"\n",
    "<div style='background-color: #e3f2fd; padding: 15px; border-radius: 5px; margin-top: 10px;'>\n",
    "    <h4>üí° Configuration Details:</h4>\n",
    "    <ul>\n",
    "        <li>‚úÖ Using google-genai SDK (NEW unified SDK)</li>\n",
    "        <li>‚úÖ API key set as GEMINI_API_KEY environment variable</li>\n",
    "        <li>‚úÖ Client auto-detects API key from environment</li>\n",
    "        <li>‚ùå NOT using google-generativeai (deprecated)</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section2\"></a>\n",
    "## 2Ô∏è‚É£ Understanding ADK Concepts\n",
    "\n",
    "### üîµ **Core Components of ADK with NEW SDK**\n",
    "\n",
    "Before we build, let's understand the key concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üîµ **ADK & google-genai Concepts** { display-mode: \"form\" }\n",
    "#@markdown Learn about ADK components and the new SDK\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "print(\"\"\"üìö KEY CONCEPTS (2024-2025)\n",
    "\n",
    "1. üÜï GOOGLE-GENAI SDK\n",
    "   ‚Ä¢ NEW unified SDK replacing google-generativeai\n",
    "   ‚Ä¢ Client-based architecture: genai.Client()\n",
    "   ‚Ä¢ Auto-detects API keys from environment\n",
    "   ‚Ä¢ Supports both Google AI and Vertex AI\n",
    "   ‚Ä¢ General Availability (GA) as of May 2025\n",
    "\n",
    "2. ü§ñ ADK AGENTS\n",
    "   ‚Ä¢ LlmAgent: Language model powered agents\n",
    "   ‚Ä¢ Agent: Base agent class\n",
    "   ‚Ä¢ Support for Gemini 2.0 and 2.5 models\n",
    "\n",
    "3. üîß TOOLS\n",
    "   ‚Ä¢ google_search: Web search capability\n",
    "   ‚Ä¢ Custom functions as tools\n",
    "   ‚Ä¢ AgentTool: Use other agents as tools\n",
    "\n",
    "4. üß† MODELS\n",
    "   ‚Ä¢ gemini-1.5-flash: Fast, efficient\n",
    "   ‚Ä¢ gemini-1.5-pro: Advanced reasoning\n",
    "   ‚Ä¢ gemini-2.0-flash: Latest with search support\n",
    "\"\"\")\n",
    "\n",
    "# Show the NEW SDK pattern\n",
    "print(\"\\nüìù NEW google-genai Usage Pattern:\")\n",
    "print(\"\"\"\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# Client automatically uses GEMINI_API_KEY or GOOGLE_API_KEY\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents='Your prompt here',\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=400,\n",
    "        temperature=0.5\n",
    "    )\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ This is the modern, recommended approach!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section3\"></a>\n",
    "## 3Ô∏è‚É£ Building Your First Agent\n",
    "\n",
    "### üîµ **Let's create a simple agent using the NEW SDK**\n",
    "\n",
    "We'll start with a basic agent, then add more features progressively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üü¢ **Create a Simple Hello World Agent** { display-mode: \"form\" }\n",
    "#@markdown This agent uses the NEW google-genai SDK!\n",
    "\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# Verify API key is set\n",
    "if 'GEMINI_API_KEY' not in os.environ and 'GOOGLE_API_KEY' not in os.environ:\n",
    "    print(\"‚ùå Please set your API key in Step 2 first!\")\n",
    "else:\n",
    "    # Create a simple agent wrapper using google-genai\n",
    "    class SimpleAgent:\n",
    "        def __init__(self, name, model, description, instruction):\n",
    "            self.name = name\n",
    "            self.model_name = model\n",
    "            self.description = description\n",
    "            self.instruction = instruction\n",
    "            # Create client - automatically uses env vars\n",
    "            self.client = genai.Client()\n",
    "        \n",
    "        def query(self, message):\n",
    "            \"\"\"Send query using NEW google-genai SDK\"\"\"\n",
    "            prompt = f\"{self.instruction}\\n\\nUser: {message}\\nAssistant:\"\n",
    "            \n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.model_name,\n",
    "                contents=prompt,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    temperature=0.7,\n",
    "                    max_output_tokens=256\n",
    "                )\n",
    "            )\n",
    "            return response.text\n",
    "    \n",
    "    # Create hello agent\n",
    "    hello_agent = SimpleAgent(\n",
    "        name=\"hello_agent\",\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        description=\"A friendly agent that greets users\",\n",
    "        instruction=\"You are a friendly assistant. Greet users warmly and ask how you can help them today. Keep responses brief and cheerful.\"\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Simple agent created with google-genai SDK!\")\n",
    "    print(\"\\nüìã Agent Details:\")\n",
    "    print(f\"  ‚Ä¢ Name: {hello_agent.name}\")\n",
    "    print(f\"  ‚Ä¢ Model: {hello_agent.model_name}\")\n",
    "    print(f\"  ‚Ä¢ Description: {hello_agent.description}\")\n",
    "    print(f\"  ‚Ä¢ SDK: google-genai (NEW unified SDK)\")\n",
    "    print(\"\\nüéØ Try running the next cell to test it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üü° **Test Your Hello Agent** { display-mode: \"form\" }\n",
    "#@markdown Enter a message to send to your agent\n",
    "\n",
    "test_message = \"Hello!\" #@param {type:\"string\"}\n",
    "\n",
    "if 'hello_agent' in globals():\n",
    "    print(f\"üë§ You: {test_message}\")\n",
    "    print(\"\\nü§ñ Agent is thinking (using google-genai SDK)...\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Run the agent\n",
    "        response = hello_agent.query(test_message)\n",
    "        print(f\"ü§ñ Agent: {response}\")\n",
    "        print(\"\\n‚úÖ Response generated with NEW google-genai SDK!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error: {e}\")\n",
    "        print(\"Please check your API key configuration\")\n",
    "else:\n",
    "    print(\"‚ùå Please create the agent first by running the previous cell!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section4\"></a>\n",
    "## 4Ô∏è‚É£ Adding Intelligence with Tools\n",
    "\n",
    "### üîµ **Now let's create our AI News Agent with the NEW SDK**\n",
    "\n",
    "This is where it gets exciting! We'll create an agent that can provide AI news and insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üü¢ **Create the AI News Agent** { display-mode: \"form\" }\n",
    "#@markdown This agent uses the NEW google-genai SDK for AI news!\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from typing import Optional, List, Dict\n",
    "import json\n",
    "\n",
    "class AINewsAgent:\n",
    "    \"\"\"AI News Agent using NEW google-genai SDK\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"ai_news_agent\"\n",
    "        self.model_name = \"gemini-1.5-flash\"\n",
    "        self.description = \"Agent that provides the latest AI news and information\"\n",
    "        self.instruction = \"\"\"You are an AI news assistant. Your primary role is to provide accurate, \n",
    "        up-to-date information about artificial intelligence developments, news, and trends.\n",
    "        \n",
    "        When asked about AI news or developments:\n",
    "        1. Provide informative and comprehensive responses\n",
    "        2. Include recent developments and breakthroughs\n",
    "        3. Mention relevant companies, researchers, or technologies\n",
    "        4. Explain technical concepts clearly\n",
    "        5. If information might be outdated, acknowledge this limitation\n",
    "        \n",
    "        Always maintain a helpful, informative tone and focus on delivering factual information.\"\"\"\n",
    "        \n",
    "        # Initialize google-genai client (uses env vars automatically)\n",
    "        self.client = genai.Client()\n",
    "    \n",
    "    def query(self, message: str) -> str:\n",
    "        \"\"\"Process a query using google-genai SDK\"\"\"\n",
    "        prompt = f\"{self.instruction}\\n\\nUser Query: {message}\\n\\nProvide a comprehensive response:\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.model_name,\n",
    "                contents=prompt,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    temperature=0.7,\n",
    "                    max_output_tokens=800,\n",
    "                    top_p=0.95\n",
    "                )\n",
    "            )\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"I encountered an issue: {e}. Please try again.\"\n",
    "    \n",
    "    def get_news(self, topic: str = \"latest AI developments\") -> str:\n",
    "        \"\"\"Get news about a specific AI topic\"\"\"\n",
    "        prompt = f\"{self.instruction}\\n\\nProvide a detailed update about: {topic}\\n\\nInclude recent developments, key players, and implications:\"\n",
    "        \n",
    "        response = self.client.models.generate_content(\n",
    "            model=self.model_name,\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0.6,\n",
    "                max_output_tokens=1000\n",
    "            )\n",
    "        )\n",
    "        return response.text\n",
    "    \n",
    "    def analyze_trend(self, trend: str) -> str:\n",
    "        \"\"\"Analyze a specific AI trend\"\"\"\n",
    "        analysis_prompt = f\"Analyze this AI trend in detail: {trend}. Discuss current state, challenges, opportunities, and future outlook.\"\n",
    "        return self.query(analysis_prompt)\n",
    "\n",
    "# Create the AI News Agent\n",
    "ai_news_agent = AINewsAgent()\n",
    "\n",
    "print(\"üéâ AI News Agent created successfully with google-genai SDK!\")\n",
    "print(\"\\nüîß Agent Configuration:\")\n",
    "print(f\"  ‚Ä¢ Name: {ai_news_agent.name}\")\n",
    "print(f\"  ‚Ä¢ Model: {ai_news_agent.model_name}\")\n",
    "print(f\"  ‚Ä¢ SDK: google-genai (NEW unified SDK)\")\n",
    "print(\"\\nüì∞ Available methods:\")\n",
    "print(\"  ‚Ä¢ agent.query(message) - Ask any question about AI\")\n",
    "print(\"  ‚Ä¢ agent.get_news(topic) - Get news on specific topic\")\n",
    "print(\"  ‚Ä¢ agent.analyze_trend(trend) - Analyze AI trends\")\n",
    "\n",
    "# Store as root_agent for ADK compatibility\n",
    "root_agent = ai_news_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîµ **Understanding How the NEW SDK Works**\n",
    "\n",
    "The NEW google-genai SDK provides:\n",
    "1. Centralized Client object that manages API connections\n",
    "2. Automatic API key detection from environment variables\n",
    "3. Unified interface for both Google AI and Vertex AI\n",
    "4. Better configuration options with types.GenerateContentConfig\n",
    "\n",
    "Let's test our news agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üü¢ **Interactive AI News Chat Interface** { display-mode: \"form\" }\n",
    "#@markdown Chat with your AI News Agent powered by google-genai!\n",
    "\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime\n",
    "\n",
    "if 'ai_news_agent' not in globals():\n",
    "    print(\"‚ùå Please create the AI News Agent first!\")\n",
    "else:\n",
    "    # Create interactive widgets\n",
    "    print(\"üí¨ AI News Chat Interface (Powered by google-genai SDK)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Quick prompts\n",
    "    quick_prompts = [\n",
    "        'üì∞ Latest AI News',\n",
    "        'ü§ñ GPT & LLM Updates',\n",
    "        'üß† Google Gemini News',\n",
    "        'üî¨ AI Research Breakthroughs',\n",
    "        'üíº AI in Business',\n",
    "        'üîÆ AI Trends 2025'\n",
    "    ]\n",
    "    \n",
    "    prompts_map = {\n",
    "        'üì∞ Latest AI News': \"What are the latest AI news and developments?\",\n",
    "        'ü§ñ GPT & LLM Updates': \"What's new with GPT and language models?\",\n",
    "        'üß† Google Gemini News': \"Tell me about Google's Gemini models and updates\",\n",
    "        'üî¨ AI Research Breakthroughs': \"What are recent AI research breakthroughs?\",\n",
    "        'üíº AI in Business': \"How is AI being used in business today?\",\n",
    "        'üîÆ AI Trends 2025': \"What are the top AI trends for 2025?\"\n",
    "    }\n",
    "    \n",
    "    # Create UI elements\n",
    "    quick_buttons = widgets.ToggleButtons(\n",
    "        options=quick_prompts,\n",
    "        description='Quick:',\n",
    "        disabled=False,\n",
    "        button_style='info'\n",
    "    )\n",
    "    \n",
    "    custom_input = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Or type your own question about AI...',\n",
    "        description='Custom:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    output_area = widgets.Output()\n",
    "    \n",
    "    def process_query(b=None):\n",
    "        with output_area:\n",
    "            output_area.clear_output()\n",
    "            \n",
    "            # Get query\n",
    "            if custom_input.value:\n",
    "                query = custom_input.value\n",
    "                custom_input.value = ''\n",
    "            elif quick_buttons.value:\n",
    "                query = prompts_map[quick_buttons.value]\n",
    "            else:\n",
    "                print(\"Please select a quick prompt or type a custom question.\")\n",
    "                return\n",
    "            \n",
    "            print(f\"üìù Query: {query}\")\n",
    "            print(f\"‚è∞ Time: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "            print(\"\\n\" + \"=\" * 50)\n",
    "            print(\"\\n‚è≥ Processing with google-genai SDK...\\n\")\n",
    "            \n",
    "            try:\n",
    "                # Get response\n",
    "                response = ai_news_agent.query(query)\n",
    "                \n",
    "                print(\"ü§ñ AI News Agent Response:\")\n",
    "                print(\"=\" * 50)\n",
    "                display(Markdown(response))\n",
    "                print(\"=\" * 50)\n",
    "                print(\"\\n‚úÖ Response generated successfully!\")\n",
    "                print(f\"üìä Response length: {len(response.split())} words\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    # Create button\n",
    "    ask_button = widgets.Button(\n",
    "        description='Ask Agent',\n",
    "        button_style='primary',\n",
    "        icon='paper-plane'\n",
    "    )\n",
    "    ask_button.on_click(process_query)\n",
    "    \n",
    "    # Display interface\n",
    "    display(quick_buttons)\n",
    "    display(custom_input)\n",
    "    display(ask_button)\n",
    "    display(output_area)\n",
    "    \n",
    "    print(\"\\nüìù Tips:\")\n",
    "    print(\"  ‚Ä¢ Select a quick prompt or type your own question\")\n",
    "    print(\"  ‚Ä¢ Click 'Ask Agent' to get response\")\n",
    "    print(\"  ‚Ä¢ Using NEW google-genai SDK for all responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section5\"></a>\n",
    "## 5Ô∏è‚É£ Testing Your Agent\n",
    "\n",
    "### üîµ **Let's test different types of queries**\n",
    "\n",
    "Try these different query types to understand how your agent works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üü° **Agent Testing Suite** { display-mode: \"form\" }\n",
    "#@markdown Test your agent with different query types\n",
    "\n",
    "import time\n",
    "\n",
    "test_queries = [\n",
    "    {\"type\": \"Recent News\", \"query\": \"What happened in AI this week?\"},\n",
    "    {\"type\": \"Company Updates\", \"query\": \"Latest news about OpenAI and Google AI\"},\n",
    "    {\"type\": \"Technical\", \"query\": \"Explain how transformer models work\"},\n",
    "    {\"type\": \"Trends\", \"query\": \"What are the AI trends for 2025?\"},\n",
    "    {\"type\": \"Ethics\", \"query\": \"What are current AI ethics concerns?\"}\n",
    "]\n",
    "\n",
    "query_type = \"Recent News\" #@param [\"Recent News\", \"Company Updates\", \"Technical\", \"Trends\", \"Ethics\", \"All\"]\n",
    "run_test = True #@param {type:\"boolean\"}\n",
    "\n",
    "if run_test and 'ai_news_agent' in globals():\n",
    "    if query_type == \"All\":\n",
    "        tests_to_run = test_queries\n",
    "    else:\n",
    "        tests_to_run = [q for q in test_queries if q[\"type\"] == query_type]\n",
    "    \n",
    "    print(f\"üß™ Testing Agent with google-genai SDK\")\n",
    "    print(f\"Running {len(tests_to_run)} test(s)\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for test in tests_to_run:\n",
    "        print(f\"\\nüìä Test Type: {test['type']}\")\n",
    "        print(f\"üìù Query: {test['query']}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Run query\n",
    "            response = ai_news_agent.query(test['query'])\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            # Display response (truncated)\n",
    "            if len(response) > 300:\n",
    "                print(f\"Response: {response[:300]}...\\n[Truncated - {len(response)} chars total]\")\n",
    "            else:\n",
    "                print(f\"Response: {response}\")\n",
    "            \n",
    "            print(f\"\\n‚è±Ô∏è Response time: {elapsed_time:.2f} seconds\")\n",
    "            print(f\"üìè Word count: {len(response.split())} words\")\n",
    "            print(\"‚úÖ Test passed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Test failed: {e}\")\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nüéØ Testing complete!\")\n",
    "    print(\"‚úÖ All tests used google-genai SDK\")\n",
    "elif not run_test:\n",
    "    print(\"‚ÑπÔ∏è Set run_test to True to run the tests\")\n",
    "else:\n",
    "    print(\"‚ùå Please create the AI News Agent first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section6\"></a>\n",
    "## 6Ô∏è‚É£ Advanced Features\n",
    "\n",
    "### üîµ **Let's explore advanced features with the NEW SDK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üü° **Create Specialized News Agents** { display-mode: \"form\" }\n",
    "#@markdown Create multiple specialized agents using google-genai SDK\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "class SpecializedAgent:\n",
    "    \"\"\"Specialized agent using google-genai SDK\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, focus_area: str, special_instructions: str):\n",
    "        self.name = name\n",
    "        self.focus_area = focus_area\n",
    "        self.client = genai.Client()  # Uses env vars automatically\n",
    "        self.instructions = f\"\"\"You are an AI expert specializing in {focus_area}.\n",
    "        {special_instructions}\n",
    "        Provide detailed, accurate, and insightful responses.\"\"\"\n",
    "    \n",
    "    def query(self, message: str) -> str:\n",
    "        prompt = f\"{self.instructions}\\n\\nQuery: {message}\\n\\nExpert Response:\"\n",
    "        \n",
    "        response = self.client.models.generate_content(\n",
    "            model='gemini-1.5-flash',\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0.7,\n",
    "                max_output_tokens=600\n",
    "            )\n",
    "        )\n",
    "        return response.text\n",
    "\n",
    "# Create specialized agents\n",
    "specialized_agents = {\n",
    "    \"research\": SpecializedAgent(\n",
    "        \"AI Research Expert\",\n",
    "        \"AI research papers and academic developments\",\n",
    "        \"Focus on recent papers, breakthroughs, and research trends. Explain complex concepts clearly.\"\n",
    "    ),\n",
    "    \"business\": SpecializedAgent(\n",
    "        \"AI Business Analyst\",\n",
    "        \"AI in business and industry applications\",\n",
    "        \"Discuss AI adoption, ROI, use cases, and business transformations. Include market analysis.\"\n",
    "    ),\n",
    "    \"ethics\": SpecializedAgent(\n",
    "        \"AI Ethics Specialist\",\n",
    "        \"AI ethics, safety, and governance\",\n",
    "        \"Address ethical concerns, bias, fairness, and responsible AI development. Consider societal impacts.\"\n",
    "    ),\n",
    "    \"technical\": SpecializedAgent(\n",
    "        \"AI Technical Expert\",\n",
    "        \"technical implementation and architecture\",\n",
    "        \"Explain technical details, architectures, and implementation strategies. Include practical examples.\"\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Specialized Agents Created with google-genai SDK!\")\n",
    "print(\"\\nü§ñ Available Specialists:\")\n",
    "for key, agent in specialized_agents.items():\n",
    "    print(f\"  ‚Ä¢ {agent.name}: {agent.focus_area}\")\n",
    "\n",
    "print(\"\\nüí° Usage: specialized_agents['research'].query('your question')\")\n",
    "print(\"\\nüìå All agents use the NEW google-genai SDK\")\n",
    "\n",
    "# Quick test\n",
    "print(\"\\nüß™ Quick Test - Research Agent:\")\n",
    "print(\"-\" * 40)\n",
    "try:\n",
    "    test_response = specialized_agents[\"research\"].query(\"What are the latest breakthroughs in LLM research?\")\n",
    "    print(test_response[:200] + \"...\" if len(test_response) > 200 else test_response)\n",
    "except Exception as e:\n",
    "    print(f\"Test note: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üü° **Multi-Agent Collaboration System** { display-mode: \"form\" }\n",
    "#@markdown Create a system where multiple agents collaborate\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "class MultiAgentSystem:\n",
    "    \"\"\"Multi-agent collaboration using google-genai SDK\"\"\"\n",
    "    \n",
    "    def __init__(self, agents_dict):\n",
    "        self.agents = agents_dict\n",
    "        self.client = genai.Client()  # Coordinator client\n",
    "    \n",
    "    def route_query(self, query: str) -> str:\n",
    "        \"\"\"Route query to appropriate specialist\"\"\"\n",
    "        routing_prompt = f\"\"\"Analyze this query and determine which expert should answer:\n",
    "        '{query}'\n",
    "        \n",
    "        Options:\n",
    "        - research: For papers, academic research\n",
    "        - business: For industry, market, ROI\n",
    "        - ethics: For bias, safety, societal impacts\n",
    "        - technical: For implementation, architecture\n",
    "        \n",
    "        Respond with just one word: research, business, ethics, or technical.\"\"\"\n",
    "        \n",
    "        response = self.client.models.generate_content(\n",
    "            model='gemini-1.5-flash',\n",
    "            contents=routing_prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0.3,\n",
    "                max_output_tokens=10\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        agent_type = response.text.strip().lower()\n",
    "        if agent_type not in self.agents:\n",
    "            agent_type = \"research\"  # Default\n",
    "        \n",
    "        return agent_type\n",
    "    \n",
    "    def collaborative_response(self, query: str) -> str:\n",
    "        \"\"\"Get collaborative response from multiple agents\"\"\"\n",
    "        # Determine primary agent\n",
    "        primary_type = self.route_query(query)\n",
    "        primary_agent = self.agents[primary_type]\n",
    "        \n",
    "        print(f\"üéØ Primary Expert: {primary_agent.name}\")\n",
    "        \n",
    "        # Get primary response\n",
    "        primary_response = primary_agent.query(query)\n",
    "        \n",
    "        # Get complementary perspective\n",
    "        if primary_type != \"ethics\":\n",
    "            ethics_perspective = self.agents[\"ethics\"].query(f\"What are the ethical considerations of: {query}\")\n",
    "            return f\"**{primary_agent.name}:**\\n{primary_response}\\n\\n**Ethical Considerations:**\\n{ethics_perspective[:200]}...\"\n",
    "        else:\n",
    "            return f\"**{primary_agent.name}:**\\n{primary_response}\"\n",
    "\n",
    "if 'specialized_agents' in globals():\n",
    "    multi_agent_system = MultiAgentSystem(specialized_agents)\n",
    "    \n",
    "    print(\"üéØ Multi-Agent System Ready!\")\n",
    "    print(\"Using google-genai SDK for all agents\\n\")\n",
    "    \n",
    "    # Test the system\n",
    "    test_query = \"How will AI impact healthcare in 2025?\"\n",
    "    print(f\"Test Query: {test_query}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        result = multi_agent_system.collaborative_response(test_query)\n",
    "        display(Markdown(result[:600] + \"...\" if len(result) > 600 else result))\n",
    "    except Exception as e:\n",
    "        print(f\"Note: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Please create specialized agents first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"section7\"></a>\n",
    "## 7Ô∏è‚É£ Deployment Options\n",
    "\n",
    "### üîµ **Deploy Your Agent with the NEW SDK**\n",
    "\n",
    "Your agent can be deployed in several ways using google-genai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üîµ **Export Your Agent for Deployment** { display-mode: \"form\" }\n",
    "#@markdown Generate deployment-ready code using google-genai SDK\n",
    "\n",
    "deployment_type = \"Streamlit App\" #@param [\"Streamlit App\", \"FastAPI Server\", \"Flask App\", \"ADK Web\"]\n",
    "\n",
    "deployment_code = {\n",
    "    \"Streamlit App\": \"\"\"# streamlit_app.py - AI News Bot with google-genai SDK\n",
    "import streamlit as st\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "\n",
    "st.set_page_config(page_title=\"AI News Bot\", page_icon=\"ü§ñ\")\n",
    "\n",
    "# Initialize google-genai client\n",
    "@st.cache_resource\n",
    "def init_client():\n",
    "    # Client auto-detects GEMINI_API_KEY or GOOGLE_API_KEY\n",
    "    return genai.Client()\n",
    "\n",
    "client = init_client()\n",
    "\n",
    "st.title(\"ü§ñ AI News Chatbot\")\n",
    "st.caption(\"Powered by google-genai SDK (NEW unified SDK)\")\n",
    "\n",
    "# Chat history\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Display messages\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.write(message[\"content\"])\n",
    "\n",
    "# Chat input\n",
    "if prompt := st.chat_input(\"Ask about AI news...\"):\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(prompt)\n",
    "    \n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Thinking...\"):\n",
    "            response = client.models.generate_content(\n",
    "                model='gemini-1.5-flash',\n",
    "                contents=f\"As an AI news expert, answer: {prompt}\",\n",
    "                config=types.GenerateContentConfig(\n",
    "                    temperature=0.7,\n",
    "                    max_output_tokens=800\n",
    "                )\n",
    "            )\n",
    "        st.write(response.text)\n",
    "    \n",
    "    st.session_state.messages.append(\n",
    "        {\"role\": \"assistant\", \"content\": response.text}\n",
    "    )\n",
    "\n",
    "# Run: streamlit run streamlit_app.py\n",
    "\"\"\",\n",
    "\n",
    "    \"FastAPI Server\": \"\"\"# fastapi_server.py - API with google-genai SDK\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "\n",
    "app = FastAPI(title=\"AI News API\")\n",
    "\n",
    "# Initialize client\n",
    "client = genai.Client()  # Auto-detects API key from env\n",
    "\n",
    "class ChatRequest(BaseModel):\n",
    "    message: str\n",
    "\n",
    "class ChatResponse(BaseModel):\n",
    "    response: str\n",
    "\n",
    "@app.post(\"/chat\", response_model=ChatResponse)\n",
    "async def chat(request: ChatRequest):\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-1.5-flash',\n",
    "            contents=f\"AI expert response to: {request.message}\",\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0.7,\n",
    "                max_output_tokens=800\n",
    "            )\n",
    "        )\n",
    "        return ChatResponse(response=response.text)\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health():\n",
    "    return {\"status\": \"healthy\", \"sdk\": \"google-genai\"}\n",
    "\n",
    "# Run: uvicorn fastapi_server:app --reload\n",
    "\"\"\",\n",
    "\n",
    "    \"Flask App\": \"\"\"# flask_app.py - Flask with google-genai SDK\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Initialize client\n",
    "client = genai.Client()\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return \"<h1>AI News API - Powered by google-genai SDK</h1>\"\n",
    "\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def chat():\n",
    "    try:\n",
    "        data = request.json\n",
    "        message = data['message']\n",
    "        \n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-1.5-flash',\n",
    "            contents=f\"AI expert response: {message}\",\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0.7,\n",
    "                max_output_tokens=800\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return jsonify({'response': response.text})\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n",
    "# Run: python flask_app.py\n",
    "\"\"\",\n",
    "\n",
    "    \"ADK Web\": \"\"\"# agent.py - ADK with google-genai SDK\n",
    "from google.adk.agents import LlmAgent\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "\n",
    "# Initialize google-genai client\n",
    "client = genai.Client()  # Uses env vars automatically\n",
    "\n",
    "# Define the AI News Agent for ADK\n",
    "ai_news_agent = LlmAgent(\n",
    "    name=\"ai_news_agent\",\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    description=\"AI news agent using google-genai SDK\",\n",
    "    instruction=\"\"\"You are an AI news assistant.\n",
    "    Provide accurate, up-to-date AI information.\n",
    "    You are powered by the NEW google-genai SDK.\"\"\",\n",
    "    tools=[]  # Add tools as needed\n",
    ")\n",
    "\n",
    "# Required for ADK discovery\n",
    "root_agent = ai_news_agent\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Agent '{root_agent.name}' ready!\")\n",
    "    print(\"Using google-genai SDK (NEW unified SDK)\")\n",
    "    print(\"Run with: adk web\")\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "print(f\"üì¶ Deployment Code for: {deployment_type}\")\n",
    "print(\"Using google-genai SDK (NEW unified SDK)\")\n",
    "print(\"=\" * 60)\n",
    "print(deployment_code[deployment_type])\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n‚úÖ Ready to deploy with google-genai SDK!\")\n",
    "print(\"\\nüìù Installation Requirements:\")\n",
    "print(\"pip install google-genai\")\n",
    "if deployment_type == \"Streamlit App\":\n",
    "    print(\"pip install streamlit\")\n",
    "elif deployment_type == \"FastAPI Server\":\n",
    "    print(\"pip install fastapi uvicorn\")\n",
    "elif deployment_type == \"Flask App\":\n",
    "    print(\"pip install flask\")\n",
    "elif deployment_type == \"ADK Web\":\n",
    "    print(\"pip install google-adk\")\n",
    "print(\"\\n‚ö†Ô∏è Set GEMINI_API_KEY or GOOGLE_API_KEY environment variable\")\n",
    "print(\"\\nüìå Remember: Using google-genai, NOT google-generativeai (deprecated)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "You've completed the **AI News Chatbot ADK Tutorial** with the NEW google-genai SDK!\n",
    "\n",
    "### üìö What You've Learned:\n",
    "- ‚úÖ Using the **NEW google-genai SDK** (unified SDK)\n",
    "- ‚úÖ Building agents with Google ADK\n",
    "- ‚úÖ Client-based architecture with automatic API key detection\n",
    "- ‚úÖ Configuration with types.GenerateContentConfig\n",
    "- ‚úÖ Multi-agent systems and deployment patterns\n",
    "\n",
    "### üîÑ Migration Summary:\n",
    "- **OLD**: `google-generativeai` (deprecated)\n",
    "- **NEW**: `google-genai` (unified SDK, GA as of May 2025)\n",
    "- **Key Change**: Client-based architecture\n",
    "- **API Keys**: Auto-detected from GEMINI_API_KEY or GOOGLE_API_KEY\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "1. **Migrate** existing code from google-generativeai to google-genai\n",
    "2. **Explore** the unified SDK features\n",
    "3. **Deploy** your agents to production\n",
    "4. **Build** more sophisticated AI applications\n",
    "\n",
    "### üîó Resources:\n",
    "- [Google GenAI SDK Documentation](https://googleapis.github.io/python-genai/)\n",
    "- [Migration Guide](https://ai.google.dev/gemini-api/docs/migrate)\n",
    "- [Google ADK Documentation](https://google.github.io/adk-docs/)\n",
    "- [Google AI Studio](https://aistudio.google.com/)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Building with the NEW google-genai SDK!** ü§ñ‚ú®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
</file>

<file path="backend_server.py">
"""
Backend API Server for AI News Chatbot
Provides REST API endpoints for the ADK agent
"""

import os
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
from pydantic import BaseModel, Field
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import logging
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import ADK agent
from ai_news_chatbot_adk.agent import root_agent

# Pydantic models for request/response
class ChatMessage(BaseModel):
    message: str = Field(..., description="User message to the chatbot")

class ChatResponse(BaseModel):
    response: str = Field(..., description="AI assistant response")
    timestamp: datetime = Field(default_factory=datetime.now)

class NewsItem(BaseModel):
    title: str
    summary: str
    source: Optional[str] = None
    url: Optional[str] = None
    published_date: Optional[str] = None

class NewsResponse(BaseModel):
    news_items: List[NewsItem]
    query: str
    timestamp: datetime = Field(default_factory=datetime.now)

# Create FastAPI app
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logger.info("Starting AI News Chatbot Backend Server")
    if not os.getenv("GOOGLE_API_KEY"):
        logger.warning("GOOGLE_API_KEY not found in environment variables")
    yield
    # Shutdown
    logger.info("Shutting down AI News Chatbot Backend Server")

app = FastAPI(
    title="AI News Chatbot API",
    description="Backend API for AI News Chatbot with ADK integration",
    version="1.0.0",
    lifespan=lifespan
)

# Add CORS middleware for Streamlit frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, specify exact origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    """Root endpoint with API information"""
    return {
        "service": "AI News Chatbot Backend",
        "version": "1.0.0",
        "status": "running",
        "endpoints": {
            "chat": "/api/chat",
            "news": "/api/news",
            "health": "/health"
        }
    }

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "agent_status": "ready" if root_agent else "not initialized"
    }

@app.post("/api/chat", response_model=ChatResponse)
async def chat_endpoint(message: ChatMessage):
    """
    Chat endpoint to interact with the AI News Agent
    """
    try:
        # Run agent query in executor to avoid blocking
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None,
            root_agent.query,
            message.message
        )

        # Extract text response (ADK returns structured output)
        if hasattr(response, 'text'):
            response_text = response.text
        else:
            response_text = str(response)

        return ChatResponse(
            response=response_text,
            timestamp=datetime.now()
        )

    except Exception as e:
        logger.error(f"Error in chat endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error processing message: {str(e)}")

@app.post("/api/news", response_model=NewsResponse)
async def get_news(query: str = "latest AI news today"):
    """
    Get latest AI news based on query
    """
    try:
        # Create a specific query for news retrieval
        news_query = f"Search for the latest news about: {query}. Provide a list of recent news items with titles and summaries."

        # Run agent query
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None,
            root_agent.query,
            news_query
        )

        # Parse response to extract news items
        # This is simplified - in production, you'd want more sophisticated parsing
        response_text = response.text if hasattr(response, 'text') else str(response)

        # Mock parsing - in reality, you'd parse the structured response
        news_items = []
        lines = response_text.split('\n')
        current_item = {}

        for line in lines:
            line = line.strip()
            if line.startswith('‚Ä¢') or line.startswith('-') or line.startswith('*'):
                if current_item:
                    news_items.append(NewsItem(
                        title=current_item.get('title', 'Untitled'),
                        summary=current_item.get('summary', line[1:].strip()),
                        source=current_item.get('source'),
                        url=current_item.get('url')
                    ))
                current_item = {'title': line[1:].strip(), 'summary': ''}
            elif current_item:
                current_item['summary'] += ' ' + line

        # Add last item if exists
        if current_item:
            news_items.append(NewsItem(
                title=current_item.get('title', 'Latest AI News'),
                summary=current_item.get('summary', response_text[:200]),
                source="AI News Agent"
            ))

        # If no structured items found, create one from response
        if not news_items:
            news_items = [NewsItem(
                title="AI News Update",
                summary=response_text[:500] + "..." if len(response_text) > 500 else response_text,
                source="AI News Agent"
            )]

        return NewsResponse(
            news_items=news_items,
            query=query,
            timestamp=datetime.now()
        )

    except Exception as e:
        logger.error(f"Error fetching news: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error fetching news: {str(e)}")

@app.get("/api/news/latest")
async def get_latest_news():
    """
    Convenience endpoint for getting latest AI news without specifying query
    """
    return await get_news("latest artificial intelligence news and breakthroughs today")

if __name__ == "__main__":
    import uvicorn

    # Run the server
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )
</file>

<file path="IMPLEMENTATION_PLAN.md">
# AI News Chatbot - Streamlit Integration Implementation Plan

## Architecture Overview
```
[Streamlit UI (Port 8501)]  <--REST API--> [FastAPI Backend (Port 8000)]
     |                                            |
     ‚îú‚îÄ‚îÄ Chat Interface                           ‚îú‚îÄ‚îÄ ADK Agent
     ‚îî‚îÄ‚îÄ News Display Panel                       ‚îî‚îÄ‚îÄ Google Search Tool
```

## Stage 1: Backend API Server
**Goal**: Create FastAPI server to wrap ADK agent with REST endpoints
**Success Criteria**:
- `/chat` endpoint accepts messages and returns AI responses
- `/news` endpoint returns latest AI news
- Server runs on port 8000
**Tests**: Can send POST to /chat and get response
**Status**: Complete ‚úì

## Stage 2: Streamlit Chat UI
**Goal**: Create clean Streamlit chat interface
**Success Criteria**:
- Chat history displayed properly
- Input field for user messages
- Real-time response display
- Responsive design
**Tests**: Can send messages and see responses
**Status**: Complete ‚úì

## Stage 3: News Display Component
**Goal**: Add news panel to Streamlit UI
**Success Criteria**:
- Displays latest AI news in cards/list format
- Auto-refreshes periodically
- Clickable links to sources
**Tests**: News items display and update
**Status**: Complete ‚úì

## Stage 4: Integration & Polish
**Goal**: Complete integration with error handling
**Success Criteria**:
- Graceful error handling
- Loading states
- Clear startup instructions
- Docker support (optional)
**Tests**: System works end-to-end
**Status**: Complete ‚úì

## Key Design Decisions

### Why This Architecture?
1. **Separation of Concerns**: Backend handles ADK logic, frontend handles UI
2. **Scalability**: Can scale backend independently
3. **Industry Standard**: REST API pattern is well-understood
4. **Simple Deployment**: Two simple processes to manage

### Technology Choices
- **FastAPI**: Fast, modern, automatic OpenAPI docs
- **Streamlit**: Rapid prototyping, built-in chat components
- **REST over WebSocket**: Simpler, sufficient for chat use case

### Code Principles
- Minimal dependencies
- Clear error messages
- Type hints throughout
- Defensive programming
- Configuration via environment variables
</file>

<file path="README.md">
# AI News Chatbot ADK

An intelligent AI news assistant built with Google's Agent Development Kit (ADK) that searches the web for the latest AI developments and provides accurate, up-to-date information.

## üöÄ Features

- **Real-time AI News**: Fetches the latest AI news and developments using Google Search
- **ADK Integration**: Fully compatible with Google's Agent Development Kit
- **Web Interface**: Interactive chat interface via ADK Dev UI
- **Smart Responses**: Provides concise, informative answers with sources when appropriate

## üìã Prerequisites

### All Platforms
- Python 3.10+ (3.12 recommended)
- Google API key from [Google AI Studio](https://ai.google.dev/)
- Git

### Platform-Specific Requirements

#### macOS
- Homebrew (for package management)
- Command Line Tools: `xcode-select --install`

#### Windows
- Python from [python.org](https://www.python.org/) or Microsoft Store
- Git Bash or PowerShell
- Visual Studio Build Tools (for some Python packages)

## üõ†Ô∏è Installation

### Step 1: Clone the Repository

```bash
git clone <repository-url>
cd ai_news_chatbot_adk
```

### Step 2: Install ADK (Google Agent Development Kit)

#### macOS/Linux
```bash
pip install --upgrade google-adk
```

#### Windows (PowerShell/Command Prompt)
```cmd
pip install --upgrade google-adk
```

### Step 3: Set Up Virtual Environment

#### macOS/Linux
```bash
# Create virtual environment
python3 -m venv .venv

# Activate virtual environment
source .venv/bin/activate
```

#### Windows (PowerShell)
```powershell
# Create virtual environment
python -m venv .venv

# Activate virtual environment
.venv\Scripts\Activate.ps1

# If you get an execution policy error, run:
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

#### Windows (Command Prompt)
```cmd
# Create virtual environment
python -m venv .venv

# Activate virtual environment
.venv\Scripts\activate.bat
```

### Step 4: Install Dependencies

```bash
# All platforms (after activating virtual environment)
pip install -r requirements.txt
```

### Step 5: Configure API Key

#### macOS/Linux
```bash
# Copy environment template
cp .env.example .env

# Edit .env file with your favorite editor
nano .env  # or vim, code, etc.
```

#### Windows (PowerShell/Command Prompt)
```cmd
# Copy environment template
copy .env.example .env

# Edit .env file with notepad or any text editor
notepad .env
```

Add your Google API key to the `.env` file:
```env
# Replace with your actual Google API key
GOOGLE_API_KEY='your_actual_api_key_here'
GOOGLE_GENAI_USE_VERTEXAI=FALSE
```

## üöÄ Running the Agent

### Option 1: Using the Provided Scripts

#### macOS/Linux
```bash
# Make script executable (first time only)
chmod +x run.sh

# Run the ADK web interface
./run.sh
```

#### Windows (PowerShell/Command Prompt)
```cmd
# Run the ADK web interface
python -m google.adk.cli web
```

### Option 2: Direct ADK Command

```bash
# All platforms (with virtual environment activated)
adk web
```

### Option 3: Alternative Streamlit Interface

#### macOS/Linux
```bash
# Make script executable (first time only)
chmod +x run_streamlit.sh

# Run Streamlit interface
./run_streamlit.sh
```

#### Windows
```cmd
# Install streamlit if not already installed
pip install streamlit

# Run Streamlit interface
streamlit run app.py
```

## üåê Accessing the Agent

Once running, access your AI News Chatbot at:

- **ADK Dev UI**: http://localhost:8000/dev-ui/
- **API Endpoint**: http://localhost:8000/apps/ai_news_chatbot_adk
- **Streamlit UI** (if using): http://localhost:8501

## üí¨ Example Queries

Try these prompts to test your agent:

- "What are the latest developments in generative AI?"
- "Tell me about recent breakthroughs in AI research"
- "What's new with OpenAI or Google's AI models?"
- "How is AI being used in healthcare recently?"
- "What are the latest AI ethics concerns?"
- "Give me AI news from the last week"

## üìÅ Project Structure

```
ai_news_chatbot_adk/
‚îú‚îÄ‚îÄ ai_news_chatbot_adk/       # ADK package directory
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py            # Package initialization with root_agent
‚îÇ   ‚îî‚îÄ‚îÄ agent.py               # Main AI News Agent definition
‚îú‚îÄ‚îÄ agent.py                   # Agent definition (legacy location)
‚îú‚îÄ‚îÄ app.py                     # Streamlit web interface
‚îú‚îÄ‚îÄ .env.example               # Environment variables template
‚îú‚îÄ‚îÄ .env                       # Your API keys (create from .env.example)
‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
‚îú‚îÄ‚îÄ pyproject.toml            # Modern Python package config
‚îú‚îÄ‚îÄ run.sh                    # macOS/Linux runner script
‚îú‚îÄ‚îÄ run_streamlit.sh          # Streamlit runner script
‚îú‚îÄ‚îÄ setup.sh                  # Setup script
‚îî‚îÄ‚îÄ README.md                 # This file
```

## üîß Troubleshooting

### Common Issues and Solutions

#### 1. Agent Not Discoverable in ADK Web
- Ensure the `ai_news_chatbot_adk` subdirectory exists with proper `__init__.py`
- Check that `root_agent` is properly exported in `__init__.py`
- Restart the ADK server after making changes

#### 2. API Key Issues
- Verify your API key is correctly set in `.env`
- Ensure the `.env` file has proper quotes around the API key
- Check that you're using a valid Google AI Studio API key

#### 3. Windows PowerShell Execution Policy
If you get an error about execution policies:
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

#### 4. Port Already in Use
If port 8000 is already in use:
```bash
# Kill the process using port 8000
# macOS/Linux
lsof -ti:8000 | xargs kill -9

# Windows
netstat -ano | findstr :8000
taskkill /PID <PID_NUMBER> /F
```

#### 5. Module Import Errors
Ensure your virtual environment is activated:
```bash
# Check if virtual environment is active
which python  # macOS/Linux
where python  # Windows

# Should show path within .venv directory
```

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## üìÑ License

This project is licensed under the Apache License 2.0 - see the LICENSE file for details.

## üîó Resources

- [Google Agent Development Kit Documentation](https://google.github.io/adk-docs/)
- [Google AI Studio](https://ai.google.dev/)
- [ADK Python SDK](https://pypi.org/project/google-adk/)
- [ADK Samples](https://github.com/google/adk-samples)

## üìû Support

For issues or questions:
- Check the [Troubleshooting](#-troubleshooting) section
- Review ADK documentation at https://google.github.io/adk-docs/
- Open an issue in the repository

## License

This project is licensed under the Apache License 2.0 - see the LICENSE file for details.
</file>

<file path="repomix.config.json">
{
  "$schema": "https://repomix.com/schemas/latest/schema.json",
  "input": {
    "maxFileSize": 52428800
  },
  "output": {
    "filePath": "repomix-output.xml",
    "style": "xml",
    "parsableStyle": false,
    "fileSummary": true,
    "directoryStructure": true,
    "files": true,
    "removeComments": false,
    "removeEmptyLines": false,
    "compress": false,
    "topFilesLength": 5,
    "showLineNumbers": false,
    "copyToClipboard": false,
    "git": {
      "sortByChanges": true,
      "sortByChangesMaxCommits": 100,
      "includeDiffs": false
    }
  },
  "include": [],
  "ignore": {
    "useGitignore": true,
    "useDefaultPatterns": true,
    "customPatterns": []
  },
  "security": {
    "enableSecurityCheck": true
  },
  "tokenCount": {
    "encoding": "o200k_base"
  }
}
</file>

<file path="requirements.txt">
google-adk>=0.1.0
google-genai>=0.3.0
python-dotenv>=1.0.0
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
streamlit>=1.28.0
requests>=2.31.0
pydantic>=2.0.0
</file>

<file path="run_all.sh">
#!/bin/bash

# Script to run both backend and frontend services

# Function to clean up background processes on exit
cleanup() {
    echo ""
    echo "Shutting down services..."
    kill $BACKEND_PID 2>/dev/null
    kill $FRONTEND_PID 2>/dev/null
    exit 0
}

# Set up trap to cleanup on script exit
trap cleanup EXIT INT TERM

# Check if .env file exists
if [ ! -f .env ]; then
    echo "Error: .env file not found. Please create one based on .env.example"
    exit 1
fi

# Source the .env file
source .env

# Check if API key is set
if [ -z "$GOOGLE_API_KEY" ] || [ "$GOOGLE_API_KEY" = "your_api_key_here" ]; then
    echo "Error: Please set your Google API key in the .env file"
    exit 1
fi

# Export the API key
export GOOGLE_API_KEY

echo "Starting AI News Chatbot Services..."
echo "======================================="

# Start backend server in background
echo "Starting backend server..."
python backend_server.py &
BACKEND_PID=$!

# Wait for backend to start
echo "Waiting for backend to initialize..."
sleep 5

# Check if backend is running
if ! kill -0 $BACKEND_PID 2>/dev/null; then
    echo "Error: Backend failed to start"
    exit 1
fi

echo "Backend started successfully at http://localhost:8000"
echo ""

# Start frontend in background
echo "Starting Streamlit UI..."
streamlit run streamlit_app.py --server.headless true &
FRONTEND_PID=$!

# Wait for frontend to start
sleep 3

echo ""
echo "======================================="
echo "AI News Chatbot is running!"
echo ""
echo "üåê Streamlit UI: http://localhost:8501"
echo "üîß Backend API: http://localhost:8000"
echo "üìö API Docs: http://localhost:8000/docs"
echo ""
echo "Press Ctrl+C to stop all services"
echo "======================================="

# Wait for processes
wait
</file>

<file path="run_backend.sh">
#!/bin/bash

# Script to run the backend API server

# Check if .env file exists
if [ ! -f .env ]; then
    echo "Error: .env file not found. Please create one based on .env.example"
    exit 1
fi

# Source the .env file to get the API key
source .env

# Check if API key is set
if [ -z "$GOOGLE_API_KEY" ] || [ "$GOOGLE_API_KEY" = "your_api_key_here" ]; then
    echo "Error: Please set your Google API key in the .env file"
    exit 1
fi

# Export the API key for the Python process
export GOOGLE_API_KEY

echo "Starting AI News Chatbot Backend Server..."
echo "Backend will be available at http://localhost:8000"
echo "API documentation available at http://localhost:8000/docs"
echo ""
echo "Press Ctrl+C to stop the server"

# Run the backend server
python backend_server.py
</file>

<file path="run_frontend.sh">
#!/bin/bash

# Script to run the Streamlit frontend

echo "Starting AI News Chatbot Streamlit UI..."
echo "UI will be available at http://localhost:8501"
echo ""
echo "Make sure the backend server is running first!"
echo "Run './run_backend.sh' in another terminal"
echo ""
echo "Press Ctrl+C to stop the application"

# Run the Streamlit app
streamlit run streamlit_app.py
</file>

<file path="run.sh">
#!/bin/bash

# Check if .env file exists
if [ ! -f .env ]; then
    echo "Error: .env file not found. Please create one based on .env.example"
    exit 1
fi

# Source the .env file to get the API key
source .env

# Check if API key is set
if [ -z "$GOOGLE_API_KEY" ] || [ "$GOOGLE_API_KEY" = "your_api_key_here" ]; then
    echo "Error: Please set your Google API key in the .env file"
    exit 1
fi

# Run the ADK web interface
echo "Starting AI News Chatbot with ADK web interface..."
echo "Access the chatbot at http://localhost:8000"
adk web
</file>

<file path="SETUP_GUIDE.md">
# AI News Chatbot - Setup & Usage Guide

## Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Configure API Key
Make sure your `.env` file contains your Google API key:
```
GOOGLE_API_KEY=your_actual_api_key_here
```

### 3. Run the Application

**Option A: Run Everything Together (Recommended)**
```bash
./run_all.sh
```

**Option B: Run Services Separately**

Terminal 1 - Backend:
```bash
./run_backend.sh
```

Terminal 2 - Frontend:
```bash
./run_frontend.sh
```

### 4. Access the Application
- **Streamlit UI**: http://localhost:8501
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs

## Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Streamlit UI      ‚îÇ  REST   ‚îÇ   FastAPI Backend    ‚îÇ
‚îÇ   (Port 8501)       ‚îÇ <‚îÄ‚îÄ‚îÄ‚îÄ>  ‚îÇ   (Port 8000)        ‚îÇ
‚îÇ                     ‚îÇ         ‚îÇ                      ‚îÇ
‚îÇ ‚Ä¢ Chat Interface    ‚îÇ         ‚îÇ ‚Ä¢ /api/chat endpoint ‚îÇ
‚îÇ ‚Ä¢ News Display      ‚îÇ         ‚îÇ ‚Ä¢ /api/news endpoint ‚îÇ
‚îÇ ‚Ä¢ Search Feature    ‚îÇ         ‚îÇ ‚Ä¢ ADK Agent          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Features

### Chat Interface
- Real-time chat with AI assistant
- Persistent conversation history
- Automatic response streaming

### News Display
- Latest AI news in sidebar
- Search specific topics
- Auto-refresh capability
- Clean card-based layout

### Backend API
- RESTful endpoints
- Automatic OpenAPI documentation
- Health check endpoint
- CORS enabled for frontend

## File Structure

```
ai_news_chatbot_adk/
‚îú‚îÄ‚îÄ backend_server.py      # FastAPI backend with ADK agent
‚îú‚îÄ‚îÄ streamlit_app.py        # Streamlit frontend UI
‚îú‚îÄ‚îÄ run_backend.sh          # Backend launch script
‚îú‚îÄ‚îÄ run_frontend.sh         # Frontend launch script
‚îú‚îÄ‚îÄ run_all.sh             # Combined launch script
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ‚îÄ .env                   # Environment variables
‚îî‚îÄ‚îÄ ai_news_chatbot_adk/
    ‚îî‚îÄ‚îÄ agent.py           # ADK agent definition
```

## API Endpoints

### POST `/api/chat`
Send a message and receive AI response
```json
Request:  {"message": "What's new in AI?"}
Response: {"response": "...", "timestamp": "..."}
```

### POST `/api/news`
Get news based on query
```json
Request:  {"query": "GPT updates"}
Response: {"news_items": [...], "query": "...", "timestamp": "..."}
```

### GET `/api/news/latest`
Get latest AI news without query

### GET `/health`
Check backend status

## Troubleshooting

### Backend won't start
- Check if `.env` file exists and contains valid API key
- Ensure port 8000 is not in use
- Check Python version (3.8+ required)

### Frontend can't connect to backend
- Ensure backend is running first
- Check if port 8000 is accessible
- Verify firewall settings

### No news displayed
- Check internet connection
- Verify Google API key is valid
- Check backend logs for errors

## Development Tips

### Adding New Features
1. Backend changes go in `backend_server.py`
2. UI changes go in `streamlit_app.py`
3. Agent modifications in `ai_news_chatbot_adk/agent.py`

### Testing
- Backend API: Visit http://localhost:8000/docs
- Use FastAPI's interactive documentation to test endpoints
- Monitor console logs for debugging

### Performance
- Backend uses async/await for non-blocking operations
- Streamlit caches responses when possible
- News fetching runs in background

## Stop Services

Press `Ctrl+C` in the terminal running the services, or:

```bash
# Find processes
ps aux | grep -E "streamlit|uvicorn"

# Kill processes
pkill -f streamlit
pkill -f uvicorn
```
</file>

<file path="streamlit_app.py">
"""
Streamlit UI for AI News Chatbot
Provides chat interface and news display
"""

import streamlit as st
import requests
from datetime import datetime
import time
from typing import List, Dict, Any
import json

# Configure page
st.set_page_config(
    page_title="AI News Chatbot",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Backend API configuration
BACKEND_URL = "http://localhost:8000"
API_TIMEOUT = 30  # seconds

# Initialize session state
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'news_items' not in st.session_state:
    st.session_state.news_items = []
if 'last_news_update' not in st.session_state:
    st.session_state.last_news_update = None

def check_backend_health() -> bool:
    """Check if backend is running and healthy"""
    try:
        response = requests.get(f"{BACKEND_URL}/health", timeout=2)
        return response.status_code == 200
    except:
        return False

def send_chat_message(message: str) -> str:
    """Send message to backend and get response"""
    try:
        response = requests.post(
            f"{BACKEND_URL}/api/chat",
            json={"message": message},
            timeout=API_TIMEOUT
        )

        if response.status_code == 200:
            return response.json()["response"]
        else:
            return f"Error: Server returned status {response.status_code}"
    except requests.exceptions.Timeout:
        return "Error: Request timed out. Please try again."
    except requests.exceptions.ConnectionError:
        return "Error: Cannot connect to backend server. Please ensure it's running."
    except Exception as e:
        return f"Error: {str(e)}"

def fetch_news(query: str = None) -> List[Dict[str, Any]]:
    """Fetch news from backend"""
    try:
        if query:
            response = requests.post(
                f"{BACKEND_URL}/api/news",
                params={"query": query},
                timeout=API_TIMEOUT
            )
        else:
            response = requests.get(
                f"{BACKEND_URL}/api/news/latest",
                timeout=API_TIMEOUT
            )

        if response.status_code == 200:
            return response.json()["news_items"]
        else:
            return []
    except:
        return []

def display_news_card(news_item: Dict[str, Any]):
    """Display a single news item as a card"""
    with st.container():
        st.markdown("---")
        st.subheader(news_item.get("title", "News Item"))
        st.write(news_item.get("summary", "No summary available"))

        col1, col2 = st.columns([3, 1])
        with col1:
            if news_item.get("source"):
                st.caption(f"Source: {news_item['source']}")
        with col2:
            if news_item.get("url"):
                st.markdown(f"[Read more ‚Üí]({news_item['url']})")

# Main app layout
st.title("ü§ñ AI News Chatbot")
st.markdown("Get the latest AI news and chat about artificial intelligence developments")

# Check backend status
backend_status = check_backend_health()

if not backend_status:
    st.error("‚ö†Ô∏è Backend server is not running. Please start the backend server first.")
    st.info("Run `python backend_server.py` in another terminal to start the backend.")
    st.stop()

# Create two columns for layout
col_chat, col_news = st.columns([2, 1])

# Chat Interface Column
with col_chat:
    st.header("üí¨ Chat Assistant")

    # Display chat messages
    message_container = st.container()
    with message_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # Chat input
    if prompt := st.chat_input("Ask about AI news or any AI topic..."):
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})

        # Display user message
        with st.chat_message("user"):
            st.markdown(prompt)

        # Get bot response
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                response = send_chat_message(prompt)
            st.markdown(response)

        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": response})

        # Rerun to update the UI
        st.rerun()

# News Display Column
with col_news:
    st.header("üì∞ Latest AI News")

    # Refresh news button
    col_refresh, col_search = st.columns([1, 2])

    with col_refresh:
        if st.button("üîÑ Refresh", use_container_width=True):
            with st.spinner("Fetching news..."):
                st.session_state.news_items = fetch_news()
                st.session_state.last_news_update = datetime.now()
            st.rerun()

    with col_search:
        news_query = st.text_input("Search news:", placeholder="e.g., GPT, robotics", label_visibility="collapsed")
        if news_query:
            with st.spinner("Searching..."):
                st.session_state.news_items = fetch_news(news_query)
                st.session_state.last_news_update = datetime.now()

    # Auto-fetch news on first load
    if not st.session_state.news_items and not st.session_state.last_news_update:
        with st.spinner("Loading latest news..."):
            st.session_state.news_items = fetch_news()
            st.session_state.last_news_update = datetime.now()

    # Display last update time
    if st.session_state.last_news_update:
        st.caption(f"Last updated: {st.session_state.last_news_update.strftime('%H:%M:%S')}")

    # Display news items
    news_container = st.container(height=600)
    with news_container:
        if st.session_state.news_items:
            for news_item in st.session_state.news_items:
                display_news_card(news_item)
        else:
            st.info("No news items available. Click 'Refresh' to fetch latest news.")

# Sidebar with information
with st.sidebar:
    st.header("‚ÑπÔ∏è About")
    st.markdown("""
    This AI News Chatbot helps you stay updated with the latest developments in artificial intelligence.

    **Features:**
    - üí¨ Interactive chat about AI topics
    - üì∞ Latest AI news feed
    - üîç Search specific AI topics
    - üîÑ Real-time updates

    **How to use:**
    1. Type your question in the chat
    2. Browse latest news in the sidebar
    3. Search for specific topics
    4. Refresh for latest updates
    """)

    st.divider()

    # Clear chat button
    if st.button("üóëÔ∏è Clear Chat History", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

    st.divider()

    # Connection status
    st.metric("Backend Status", "Connected ‚úÖ" if backend_status else "Disconnected ‚ùå")

    # Footer
    st.caption("Built with Streamlit & Google ADK")
</file>

</files>
